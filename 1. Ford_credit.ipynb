{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Vanguard](datasets/vanguard.png) \n",
    "## ASSET BACKED SECURITIES - AUTO FINANCE LOAN DEFAULT PREDICTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is an Asset-Backed Security\n",
    "An asset-backed security (ABS) is a financial security collateralized by a pool of assets such as loans, leases, credit card debt, royalties or receivables. For investors, asset-backed securities are an alternative to investing in corporate debt. An ABS is similar to a mortgage-backed security, except that the underlying securities are not mortgage-based.\n",
    "\n",
    "Asset-backed securities allow issuers to generate more cash, which, in turn, is used for more lending while giving investors the opportunity to invest in a wide variety of income-generating assets. Usually, the underlying assets of an ABS are illiquid and can't be sold on their own. But pooling the assets together and creating a financial security, a process called securitization, enables the owner of the assets to make them marketable. The underlying assets of these pools may be home equity loans, automobile loans, credit card receivables, student loans or other expected cash flows. Issuers of ABS can be as creative as they desire. For example, ABS have been created based on cash flows from movie revenues, royalty payments, aircraft leases and solar photovoltaics. Just about any cash-producing situation can be securitized into an ABS.\n",
    "\n",
    "### Example of Asset-Backed Security\n",
    "Assume that Company X is in the business of making automobile loans. If a person wants to borrow money to buy a car, Company X gives that person the cash, and the person is obligated to repay the loan with a certain amount of interest. Perhaps Company X makes so many loans that it runs out of cash to continue making more loans. Company X can then package its current loans and sell them to Investment Firm X, thus receiving cash that it can use to make more loans.\n",
    "\n",
    "Investment Firm X will then sort the purchased loans into different groups called tranches. These tranches are groups of loans with similar characteristics, such as maturity, interest rate and expected delinquency rate. Next, Investment Firm X will issue securities that are similar to typical bonds on each tranche it creates.\n",
    "\n",
    "Individual investors then purchase these securities and receive the cash-flows from the underlying pool of auto loans, minus an administrative fee that Investment Firm X keeps for itself.\n",
    "\n",
    "### Typical Tranches\n",
    "Usually an ABS will have three tranches: class A, B and C. The senior tranche, A, is almost always the largest tranche and is structured to have an investment-grade rating to make it attractive to investors.\n",
    "\n",
    "The B tranche has lower credit quality and thus has a higher yield than the senior tranche. The C tranche has a lower credit rating than the B tranche and might have such poor credit quality that it can't be sold to investors. In this case, the issuer would keep the C tranche and absorb the losses.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanguard Use Case \n",
    "To predict loan default based on public data from SEC and additional economic data\n",
    "\n",
    "![Auto Loans](datasets/saupload_US-auto-loans-2017-Q1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "# import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "# from keras import optimizers\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Input, Dense, Dropout, LSTM, GRU\n",
    "# from keras.models import Model, load_model\n",
    "# from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "# from keras import regularizers\n",
    "# tf.__version__\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "# import itertools\n",
    "# import operator\n",
    "# import collections\n",
    "# from scipy.io import mmread, mmwrite\n",
    "# from random import randint\n",
    "# from sklearn import linear_model\n",
    "# from sklearn.grid_search import GridSearchCV\n",
    "# from sklearn import preprocessing as pp\n",
    "# from sklearn.svm import SVR\n",
    "# from sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier\n",
    "# from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "# from sklearn.ensemble import ExtraTreesRegressor\n",
    "# from sklearn.decomposition import PCA, KernelPCA\n",
    "# from sklearn.decomposition import NMF\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.svm import LinearSVC\n",
    "# from sklearn.linear_model import LogisticRegression, Ridge, Lasso, ElasticNet\n",
    "# import scipy.stats as stats\n",
    "# from sklearn import tree\n",
    "# from sklearn.feature_selection import f_regression\n",
    "# from sklearn.gaussian_process import GaussianProcess\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "# from sklearn import metrics\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import confusion_matrix, precision_recall_curve\n",
    "# from sklearn.metrics import recall_score, classification_report, auc, roc_curve\n",
    "# from sklearn.metrics import precision_recall_fscore_support, f1_score\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Model Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# name = \"ABS_Keras-GRU254GRU128D32D2-adam{}\".format(int(time.time()))\n",
    "#name_noTime = \"ABS_Keras-LSTM128LSTM128D32D2-adam\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#parameters to choose\n",
    "default_days = 0\n",
    "#nrows = 40_000_000\n",
    "train_split = 0.80\n",
    "model_type = 'scikit-learn'\n",
    "path = 'c:/users/ugy1/abs/'\n",
    "#rows_for_prediction = 1000\n",
    "cutOffForOriginationDate='2012-01-01'\n",
    "manualOversamplingFactor=0.0\n",
    "epochs=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features to Be Used from Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_list1=[\n",
    "    'abs_loan.cik',\n",
    "'abs_loan.assettypenumber',\n",
    "'abs_loan.assetnumber',\n",
    "'abs_loan.reportingperiodendingdate',\n",
    "'abs_loan.originatorname',\n",
    "'abs_loan.originationdate',\n",
    "'abs_loan.originalloanamount',\n",
    "'abs_loan.originalloanterm',\n",
    "'abs_loan.loanmaturitydate',\n",
    "'abs_loan.originalinterestratepercentage',\n",
    "'abs_loan.interestcalculationtypecode',\n",
    "'abs_loan.originalinterestratetypecode',\n",
    "'abs_loan.originalinterestonlytermnumber',\n",
    "'abs_loan.originalfirstpaymentdate',\n",
    "'abs_loan.underwritingindicator',\n",
    "'abs_loan.paymenttypecode',\n",
    "'abs_loan.subvented',\n",
    "'abs_loan.vehiclemanufacturername',\n",
    "'abs_loan.vehiclemodelname',\n",
    "'abs_loan.vehiclenewusedcode',\n",
    "'abs_loan.vehiclemodelyear',\n",
    "'abs_loan.vehicletypecode',\n",
    "'abs_loan.vehiclevalueamount',\n",
    "'abs_loan.vehiclevaluesourcecode',\n",
    "'abs_loan.obligorcreditscoretype',\n",
    "'abs_loan.obligorcreditscore',\n",
    "'abs_loan.obligorincomeverificationlevelcode',\n",
    "'abs_loan.obligoremploymentverificationcode',\n",
    "'abs_loan.coobligorindicator',\n",
    "'abs_loan.paymenttoincomepercentage',\n",
    "'abs_loan.obligorgeographiclocation',\n",
    "'abs_loan.servicingfeepercentage',\n",
    "'abs_loan.servicingflatfeeamount',\n",
    "'abs_loan.primaryloanservicername',\n",
    "'abs_loan.zerobalancecode']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# columns to be used\n",
    "use_list=[\n",
    "    'abs_loan.cik',\n",
    " #'abs_loan.accessionnumber',\n",
    " 'abs_loan.assettypenumber',\n",
    " 'abs_loan.assetnumber',\n",
    " 'abs_loan.reportingperiodbeginningdate',\n",
    " 'abs_loan.reportingperiodendingdate',\n",
    " 'abs_loan.originatorname',\n",
    " 'abs_loan.originationdate',\n",
    " 'abs_loan.originalloanamount',\n",
    " 'abs_loan.originalloanterm',\n",
    " 'abs_loan.loanmaturitydate',\n",
    " 'abs_loan.originalinterestratepercentage',\n",
    " #'interestcalculationtypecode',\n",
    " #'abs_loan.originalinterestratetypecode',\n",
    " 'abs_loan.originalinterestonlytermnumber',\n",
    " 'abs_loan.originalfirstpaymentdate',\n",
    " 'abs_loan.underwritingindicator',\n",
    " 'abs_loan.graceperiodnumber',\n",
    " 'abs_loan.paymenttypecode', # included now\n",
    " 'abs_loan.subvented',\n",
    " #'vehiclemanufacturername',\n",
    " #'vehiclemodelname',\n",
    " 'abs_loan.vehiclenewusedcode',\n",
    " #'vehiclemodelyear',\n",
    " 'abs_loan.vehicletypecode',\n",
    " #'vehiclevalueamount',\n",
    " #'vehiclevaluesourcecode',\n",
    " 'abs_loan.obligorcreditscoretype',\n",
    " 'abs_loan.obligorcreditscore',\n",
    " 'abs_loan.obligorincomeverificationlevelcode',\n",
    " 'abs_loan.obligoremploymentverificationcode',\n",
    " 'abs_loan.coobligorindicator',\n",
    " 'abs_loan.paymenttoincomepercentage',\n",
    " 'abs_loan.obligorgeographiclocation',\n",
    " 'abs_loan.assetaddedindicator',\n",
    " #'remainingtermtomaturitynumber',\n",
    " 'abs_loan.reportingperiodmodificationindicator',\n",
    " #'abs_loan.servicingadvancemethodcode', # it is only a method code not relevent to non-payment\n",
    " 'abs_loan.reportingperiodbeginningloanbalanceamount',\n",
    " 'abs_loan.nextreportingperiodpaymentamountdue',\n",
    " 'abs_loan.reportingperiodinterestratepercentage',\n",
    " 'abs_loan.nextinterestratepercentage',\n",
    " 'abs_loan.servicingfeepercentage',\n",
    " 'abs_loan.servicingflatfeeamount',\n",
    " 'abs_loan.otherservicerfeeretainedbyservicer',\n",
    " ####'abs_loan.otherassesseduncollectedservicerfeeamount',\n",
    " 'abs_loan.scheduledinterestamount',\n",
    " 'abs_loan.scheduledprincipalamount',\n",
    " 'abs_loan.otherprincipaladjustmentamount',\n",
    " 'abs_loan.reportingperiodactualendbalanceamount',\n",
    " 'abs_loan.reportingperiodscheduledpaymentamount',\n",
    " ####'abs_loan.totalactualamountpaid',\n",
    " 'abs_loan.actualinterestcollectedamount',\n",
    " 'abs_loan.actualprincipalcollectedamount',\n",
    " 'abs_loan.actualothercollectedamount',\n",
    " ####'abs_loan.serviceradvancedamount',\n",
    " 'abs_loan.interestpaidthroughdate',\n",
    " 'abs_loan.zerobalanceeffectivedate',\n",
    " 'abs_loan.zerobalancecode',\n",
    " 'abs_loan.currentdelinquencystatus',\n",
    " 'abs_loan.primaryloanservicername', # added new\n",
    " #'mostrecentservicingtransferreceiveddate',\n",
    " #'assetsubjectdemandindicator',\n",
    " #'assetsubjectdemandstatuscode',\n",
    " #'repurchaseamount',\n",
    " #'demandresolutiondate',\n",
    " #'repurchasername',\n",
    " #'repurchasereplacementreasoncode',\n",
    " #'chargedoffprincipalamount',\n",
    " #'recoveredamount',\n",
    " #'modificationtypecode',\n",
    " #'paymentextendednumber',\n",
    " #'repossessedindicator',\n",
    " #'repossessedproceedsamount'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#set gpu options to adjust gpu usage\n",
    "# gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.5)\n",
    "# sess=tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40789594, 35)\n"
     ]
    }
   ],
   "source": [
    "#load data from tab delimited file\n",
    "df=pd.read_csv(path+'prod/abs_loan_Dec_to_Sep.csv', \n",
    "               usecols=use_list1, \n",
    "               sep='\\t',\n",
    "               #compression=bz2,\n",
    "               #nrows=nrows,\n",
    "               low_memory=False, \n",
    "              #index_col='abs_loan.reportingperiodendingdate', \n",
    "               parse_dates=True\n",
    "              )\n",
    "\n",
    "#remove 'abs_loan.' string from columns because 'dot' is a command in pandas\n",
    "df.columns=df.columns.str.replace('abs_loan.','')\n",
    "\n",
    "#display data shape\n",
    "print(df.shape)\n",
    "#view first five rows of all columns\n",
    "#df.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Analyse and Delete Duplicate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1725617, 1742444, 1726794, 1708978, 1696935, 1711993, 1705710,\n",
       "       1710916, 1717900, 1725585, 1694276, 1713660, 1697574, 1706612,\n",
       "       1715362, 1721745, 1694423, 1712665, 1723370, 1694919, 1704304,\n",
       "       1709987, 1718100, 1715585, 1728847, 1728028, 1730276, 1735033,\n",
       "       1736712, 1738390, 1736790, 1720749, 1733358, 1745187, 1743852,\n",
       "       1741276, 1745763, 1748011, 1745376, 1750588, 1753581, 1754189,\n",
       "       1756401, 1739276, 1754784, 1702011, 1710330, 1724588, 1699234,\n",
       "       1712182, 1734889, 1735464, 1744034, 1752578, 1725618, 1734850,\n",
       "       1742867, 1754008, 1733310, 1729361, 1741908, 1745314, 1751012,\n",
       "       1754388, 1679731, 1692310, 1693819, 1694010, 1700667, 1702777,\n",
       "       1703220, 1705002, 1708287, 1710329, 1710600, 1713736, 1718362,\n",
       "       1718592, 1721353, 1721372, 1724128, 1727820, 1736511, 1742379],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.cik.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=df[df.cik==1692310]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(504930, 35)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ford Credit'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.assettypenumber.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.drop(['assettypenumber'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['065739000282', '065739000390', '065739000406', ...,\n",
       "       '065739046141', '065739055598', '065739060947'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.assetnumber.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ford Credit', nan], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.originatorname.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001431881646960965"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.originatorname.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.drop(['originatorname'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.drop(['cik'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.duplicated(subset=['cik','assetnumber']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.duplicated(subset=['cik','assetnumber','originationdate']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.loc[df.duplicated(subset=['cik','assetnumber','reportingperiodendingdate']),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.drop_duplicates(subset=['cik','assetnumber','reportingperiodendingdate','originationdate'],keep='last', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.columns.tolist()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe Memory Usage and Datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#df.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.memory_usage(deep=True).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.head()\n",
    "#df=df.sort_values(by='originationdate', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to Draw Bar chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function to draw a bar chart \n",
    "# def draw(data, title, ylabel, sort = False, n=-1):\n",
    "#     labels = pd.value_counts(data).head().index.tolist()\n",
    "#     count_classes = pd.value_counts(data, sort).head()\n",
    "#     count_classes.plot(kind = 'bar', rot=0)\n",
    "#     plt.xticks(range(len(labels)), labels)\n",
    "#     plt.title(title)\n",
    "#     plt.ylabel(ylabel)\n",
    "#     plt.show()\n",
    "#     print('Top ',n,' counts: ','\\n',pd.value_counts(data, sort).head(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reporting Period\n",
    "we have taken reportingperiodendingdate as a proxy for the reporting period"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing values in the reporting period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.reportingperiodendingdate.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.reportingperiodendingdate.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#draw(df.reportingperiodendingdate, title='reporting period endingdate', ylabel='Number of Loans', sort = True, n=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2017-12-31', '2018-01-31', '2018-02-28', '2018-03-31',\n",
       "       '2018-04-30', '2018-05-31', '2018-06-30', '2018-07-31',\n",
       "       '2018-08-31', '2018-09-30'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.reportingperiodendingdate.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df['reportingperiodendingdate']=df.reportingperiodendingdate.replace('2018-09-28','2018-09-30')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# restrict data to a reporting period\n",
    "#df=df[df.index=='2017-11-30']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.reportingperiodendingdate.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean current deliquency days for the reporting period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.currentdelinquencystatus.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.dropna(subset=['currentdelinquencystatus'], how='all', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.currentdelinquencystatus.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.currentdelinquencystatus.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # retaining only loans with non-negative currentdelinquencystatus days\n",
    "# u=pd.value_counts(df.currentdelinquencystatus<0)\n",
    "# if len(u)<2:\n",
    "#     print('No Loans Below zero current deliquency status days')\n",
    "# else: \n",
    "#     print('Number of Loans with negative current deliquency status days :', u[1])\n",
    "#     print('Dropping ', u[1], 'rows and retaining loans with only non-negative current deliquency status days')\n",
    "#     df=df[df.currentdelinquencystatus>=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.groupby(df.reportingperiodendingdate).currentdelinquencystatus.mean().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean reporting period ending balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.groupby(df.reportingperiodendingdate).reportingperiodactualendbalanceamount.mean().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual end balance amount for all current delinquency status days by reporting period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#df.groupby(df.reportingperiodendingdate).plot(kind='scatter', x='reportingperiodactualendbalanceamount',y='currentdelinquencystatus', title='Balance due by deliquency days by reporting period')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Feature columns for Reporting period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added Column for :   reportingperiodending_2017-12-31\n",
      "Added Column for :   reportingperiodending_2018-01-31\n",
      "Added Column for :   reportingperiodending_2018-02-28\n",
      "Added Column for :   reportingperiodending_2018-03-31\n",
      "Added Column for :   reportingperiodending_2018-04-30\n",
      "Added Column for :   reportingperiodending_2018-05-31\n",
      "Added Column for :   reportingperiodending_2018-06-30\n",
      "Added Column for :   reportingperiodending_2018-07-31\n",
      "Added Column for :   reportingperiodending_2018-08-31\n",
      "Added Column for :   reportingperiodending_2018-09-30\n",
      "New Dataframe shape :  (504930, 42)\n"
     ]
    }
   ],
   "source": [
    "# create feature columns for categories within originator name \n",
    "def map_reportingperiodendingdate(*args):\n",
    "    columns = [col for col in args]\n",
    "    for column in columns:\n",
    "        if column == code:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "codes = pd.value_counts(df.reportingperiodendingdate).index.tolist()\n",
    "\n",
    "for code in codes:\n",
    "        df['reportingperiodending_{}'.format(code)] = list(map(map_reportingperiodendingdate, df.reportingperiodendingdate))\n",
    "        print('Added Column for :   reportingperiodending_'+code)\n",
    "print('New Dataframe shape : ', df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Number of Days Loans Outstanding and creating a feature column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#calculate outstanding days\n",
    "df['outstandingdays'] = pd.to_datetime(df['reportingperiodendingdate'])-pd.to_datetime(df['originationdate'])\n",
    "#draw a chart for visual look and analysis\n",
    "#draw(df.outstandingdays, title='Outstanding Days', ylabel='Number of Loans', sort = True, n=5)\n",
    "#remove days string for machine learning\n",
    "df['outstandingdays']=df.outstandingdays.map(lambda x: np.nan if pd.isnull(x) else x.days)\n",
    "#display last five rows\n",
    "#df.outstandingdays.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### current deliquency status days Vs Loan Outstanding days by the reporting period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#df.groupby(df.reportingperiodendingdate).plot(kind='scatter', x='outstandingdays',y='currentdelinquencystatus', title='Balance due by deliquency days by reporting period')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping Loans Below Zero Outstanding Days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Loans Below zero outstanding days\n"
     ]
    }
   ],
   "source": [
    "# retaining only loans with non-negative outstanding days\n",
    "u=pd.value_counts(df.outstandingdays<0)\n",
    "if len(u)<2:\n",
    "    print('No Loans Below zero outstanding days')\n",
    "else: \n",
    "    print('Number of Loans with negative outstanding days :', u[1])\n",
    "    print('Dropping ', u[1], 'rows and retaining loans with only non-negative outstanding days')\n",
    "    df=df[df.outstandingdays>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get statistics for outstanding days\n",
    "#df.outstandingdays.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean outstanding days for the reporting period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.groupby(df.reportingperiodendingdate).outstandingdays.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Number of Days Left until Maturity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#calculate days left until maturity\n",
    "df['daystomaturity'] = pd.to_datetime(df['loanmaturitydate'])-pd.to_datetime(df['reportingperiodendingdate'])\n",
    "#draw(df.daystomaturity, title='Days Left Until Maturity', ylabel='Number of Loans', sort=True, n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Feature Column for Days to Maturity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27870267    1553.0\n",
       "27870268     488.0\n",
       "27870269    1188.0\n",
       "27870270    1553.0\n",
       "27870271    1219.0\n",
       "Name: daystomaturity, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove 'days' string from the data for machine learning\n",
    "df['daystomaturity']=df.daystomaturity.map(lambda x: np.nan if pd.isnull(x) else x.days)\n",
    "# print last five rows\n",
    "df.daystomaturity.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Loans with negativedays to maturity : 1253\n",
      "Dropping  1253 rows and retaining loans with only non-negative days to maturity\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(502954, 44)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#retaining only loans with non-negative days to maturity\n",
    "u=pd.value_counts(df.daystomaturity<=0)\n",
    "if len(u)<2:\n",
    "    print('No Loans Below zero days to maturity')\n",
    "else: \n",
    "    print('Number of Loans with negativedays to maturity :', u[1])\n",
    "    print('Dropping ', u[1], 'rows and retaining loans with only non-negative days to maturity')\n",
    "    df=df[df.daystomaturity>0]\n",
    "#number of rows and columns of the dataframe\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# statistics for days to maturity\n",
    "#df.daystomaturity.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean days to maturity for the reporting period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.groupby(df.reportingperiodendingdate).daystomaturity.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outstandingdays Vs Days to maturity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df[['outstandingdays', 'daystomaturity']].boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Progra~1\\Anaconda3_4\\envs\\tf_111\\lib\\site-packages\\pandas\\core\\frame.py:3697: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "df.drop(['loanmaturitydate'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Origination Date - Removing loans before origination cutoff date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows before 2012-01-01 : 26\n",
      "Dropping  26 rows and retaining loans with origination dates after 2012-01-01\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(502928, 43)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove loans with orgination dates set for cut off earlier\n",
    "u=pd.value_counts(df.originationdate<=cutOffForOriginationDate)\n",
    "if len(u)<2:\n",
    "    print('No origination date rows fall before ',cutOffForOriginationDate )\n",
    "else: \n",
    "    print('Number of rows before',cutOffForOriginationDate ,':', u[1])\n",
    "    print('Dropping ', u[1], 'rows and retaining loans with origination dates after', cutOffForOriginationDate)\n",
    "    df=df[df.originationdate>cutOffForOriginationDate]\n",
    "#new number of rows and columns of the dataframe\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top ten mean current deliquency status by origination date and reporting period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.groupby([df.originationdate, df.reportingperiodendingdate]).currentdelinquencystatus.mean().sort_values().tail(n=10).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.groupby(df.originationdate).currentdelinquencystatus.mean().sort_values().tail(n=10).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Originators Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.originatorname.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# draw charts for originators name\n",
    "#draw(df.originatorname, title='Originators Name', ylabel='Number of Loans', sort=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Features for Originators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df['originatorname']=df.originatorname.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.originatorname.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.groupby(df.originatorname).currentdelinquencystatus.mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # create feature columns for categories within originator name \n",
    "# def map_originatorname(*args):\n",
    "#     columns = [col for col in args]\n",
    "#     for column in columns:\n",
    "#         if column == code:\n",
    "#             return 1\n",
    "#         else:\n",
    "#             return 0\n",
    "# codes = pd.value_counts(df.originatorname).index.tolist()\n",
    "\n",
    "# for code in codes:\n",
    "#         df['originator_{}'.format(code)] = list(map(map_originatorname, df.originatorname))\n",
    "#         print('Added Column for :   originator_'+code)\n",
    "# print('New Dataframe shape : ', df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # drop originator name column\n",
    "# df.drop(['originatorname'],axis=1, inplace=True)\n",
    "# # new number of rows and columns\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Loan Amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.groupby(df.reportingperiodendingdate).originalloanamount.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# draw chart for original loan amount as filered in the next variable(original_loan_in_excess) \n",
    "#original_loan_in_excess = 10000\n",
    "#draw(df.originalloanamount>original_loan_in_excess, title='Original Loan Amount', ylabel='Number of Loans', sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#draw a chart to view distribution of original loan amount\n",
    "# bins = np.linspace(0, 80000, 1000)\n",
    "# plt.hist(df.originalloanamount, bins, label='Original Loan Amount')\n",
    "# plt.legend(loc='upper right')\n",
    "# plt.title(\"Original Amount Loaned\")\n",
    "# plt.xlabel('Original Loan amount')\n",
    "# plt.ylabel('Number of Loans')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get statistics for original loan amount\n",
    "#df.originalloanamount.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Original Loan Amount Below Zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No original loan amount blank or below zero\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(502928, 43)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To remove rows with zero, non-negative or blank values for original loan amount\n",
    "\n",
    "u=pd.value_counts(df.originalloanamount<=0)\n",
    "if len(u)<2:\n",
    "    print('No original loan amount blank or below zero')\n",
    "else: \n",
    "    print('Number of original loan amount rows blank or below zero',':', u[1])\n",
    "    print('Dropping ', u[1], 'rows and retaining loans with original loan amount more than zero')\n",
    "    df=df[df.originalloanamount>0]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Loan Term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for NaN\n",
    "df.originalloanterm.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reportingperiodendingdate\n",
       "2017-12-31    65.663977\n",
       "2018-01-31    65.710352\n",
       "2018-02-28    65.747658\n",
       "2018-03-31    65.785917\n",
       "2018-04-30    65.822215\n",
       "2018-05-31    65.858109\n",
       "2018-06-30    65.899654\n",
       "2018-07-31    65.937957\n",
       "2018-08-31    65.991402\n",
       "2018-09-30    66.047955\n",
       "Name: originalloanterm, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(df.reportingperiodendingdate).originalloanterm.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# draw chart for original loan term based on the input of variable below(original_loan_term_excess)\n",
    "#original_loan_term_excess = 48\n",
    "#draw(df.originalloanterm>original_loan_term_excess, title='Original Loan Terms', ylabel='Number of Loans',sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Top ten delinquency days by the original loan term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.plot(kind='scatter', x='originalloanterm', y='currentdelinquencystatus')\n",
    "#df.groupby(df.originalloanterm).currentdelinquencystatus.mean().sort_values(ascending=False).head(10).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.originalloanterm.plot(kind='hist', bins=10, title='Original Loan Term')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#statistics for original loan term\n",
    "#df.originalloanterm.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No original loan term blank or below zero\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(502928, 43)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove rows with zero, blank or negative original loan term\n",
    "\n",
    "u=pd.value_counts(df.originalloanterm<=0)\n",
    "if len(u)<2:\n",
    "    print('No original loan term blank or below zero')\n",
    "else: \n",
    "    print('Number of original loan term rows blank or below zero',':', u[1])\n",
    "    print('Dropping ', u[1], 'rows and retaining loans with original loan term more than zero')\n",
    "    df=df[df.originalloanterm>0]\n",
    "# new number of rows and columns of the dataframe\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original loan term effect on current delinquency status days by the reporting period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#df.groupby(df.reportingperiodendingdate).plot(kind='scatter', x='originalloanterm',y='currentdelinquencystatus', title='loan term effect on deliquency days by reporting period')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original interest rate percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.originalinterestratepercentage.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    502928.000000\n",
       "mean          0.024493\n",
       "std           0.028062\n",
       "min           0.000000\n",
       "25%           0.000000\n",
       "50%           0.019000\n",
       "75%           0.043900\n",
       "max           0.219900\n",
       "Name: originalinterestratepercentage, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get statistics for originalinterestratepercentage\n",
    "df.originalinterestratepercentage.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove interest rates below zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No original interest rate blank or below zero\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(502928, 43)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop rows with blank or negative original interest rate percentage and research on zero interest rate loans\n",
    "u=pd.value_counts(df.originalinterestratepercentage<0)\n",
    "if len(u)<2:\n",
    "    print('No original interest rate blank or below zero')\n",
    "else: \n",
    "    print('Number of original interest rate rows blank or below zero',':', u[1])\n",
    "    print('Dropping ', u[1], 'rows and retaining loans with original interest rate with non-negative values')\n",
    "    df=df[df.originalinterestratepercentage>=0]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retain zero interest loans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of zero original interest rate rows : 213784\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(502928, 43)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view zero original interest rate percentage loans\n",
    "u=pd.value_counts(df.originalinterestratepercentage==0)\n",
    "if len(u)<2:\n",
    "    print('No zero original interest rate percentage')\n",
    "else: \n",
    "    print('Number of zero original interest rate rows',':', u[1])\n",
    "    #print('Dropping ', u[1], 'rows and retaining loans with original interest rate with non-negative values')\n",
    "    #df=df[df.originalinterestratepercentage>=0]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interest rate percent effect on deliquency days by reporting period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#df.groupby(df.reportingperiodendingdate).plot(kind='scatter', x='originalinterestratepercentage',y='currentdelinquencystatus', title='interest rate percent effect on deliquency days by reporting period')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Interest Rate Type Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indicate whether the interest rate on the loan is fixed, adjustable or other. 1: Fixed, 2: Adjustable, 98: Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.originalinterestratetypecode.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.originalinterestratetypecode.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are no other categories other than 1: Fixed, We will delete this columns as it is not adding any variability to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(502928, 42)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(['originalinterestratetypecode'],axis=1, inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Interest Only Term Number..dropped due to no data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indicate the number of months from origination in which the obligor is permitted to pay only interest on the loan beginning from when the loan was originated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.originalinterestonlytermnumber.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.originalinterestonlytermnumber.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are no values in this column, we will delete this column feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(502928, 41)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(['originalinterestonlytermnumber'],axis=1, inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Underwriting Indicator dropped due to all being True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indicate whether the loan met the criteria for the first level of solicitation, credit-granting or underwriting criteria used to originate the loan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([True], dtype=object)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.underwritingindicator.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(502928, 40)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(['underwritingindicator'],axis=1, inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# missing values\n",
    "#df.underwritingindicator.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df['underwritingindicator']=df.underwritingindicator.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#draw(df.underwritingindicator, title='Underwriting Indicator', ylabel='Number of Loans', sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#df.groupby(df.underwritingindicator).plot(kind='scatter', x='originalinterestratepercentage',y='currentdelinquencystatus', title='interest rate percent effect on deliquency days by reporting period')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Feature Column Underwriting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def map_underwriting_true(*args):\n",
    "#     columns = [col for col in args]\n",
    "#     for column in columns:\n",
    "#         if column == True:\n",
    "#             return 1\n",
    "#         elif column == False:\n",
    "#             return 0\n",
    "        \n",
    "# df['underwriting_true'] = list(map(map_underwriting_true, df.underwritingindicator))\n",
    "# df.drop(['underwritingindicator'], axis=1, inplace=True)\n",
    "# pd.value_counts(df.underwriting_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Underwriting TRUE current deliquency status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #df.loc[df.underwriting_true==1].currentdelinquencystatus.plot(kind='hist', bins=10)\n",
    "# print('Total :',df.loc[df.underwriting_true==1].currentdelinquencystatus.value_counts().sum())\n",
    "# df.loc[df.underwriting_true==1].currentdelinquencystatus.value_counts().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Underwriting FALSE current deliquency status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.loc[df.underwriting_true==0].currentdelinquencystatus.plot(kind='hist', bins=10)\n",
    "# print('Total :',df.loc[df.underwriting_true==0].currentdelinquencystatus.value_counts().sum())\n",
    "# df.loc[df.underwriting_true==0].currentdelinquencystatus.value_counts().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subvented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indicate yes or no as to whether a form of subsidy is received on the loan, such as cash incentives or favorable financing for the buyer. 0: No, 1: Yes - Rate Subvention, 2: Yes - Cash Rebate, 98: Yes - Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['[\"2\"]', '[\"1\",\"2\"]', '[\"0\"]', '[\"1\"]'], dtype=object)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.subvented.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df['subvented']=df.subvented.replace('[\"1\",\" 2\"]','[\"1\",\"2\"]').replace('[\"1\",\" 98\"]','[\"1\",\"98\"]').replace('[\"2\",\"1\"]', '[\"1\",\"2\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.subvented.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['subvented']=df.subvented.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#draw(df.subvented, title='Subvented', ylabel='Number of Loans', sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count        502928\n",
       "unique            4\n",
       "top       [\"1\",\"2\"]\n",
       "freq         243572\n",
       "Name: subvented, dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.subvented.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### subvented effect on original interest rate percent and current deliquency days by reporting period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#label=df.groupby([df.reportingperiodendingdate, df.subvented])\n",
    "#pd.value_counts(df.reportingperiodendingdate).keys().tolist()\n",
    "#pd.value_counts(df.subvented).keys().tolist()\n",
    "# sorted_obj=['[\"0\"]','[\"1\"]','[\"2\"]''[\"98\"]']\n",
    "# label=[]\n",
    "# for i in pd.value_counts(df.reportingperiodendingdate).sort_values(ascending=True).keys().tolist():\n",
    "#     for j in pd.value_counts(df.subvented).sort_values(sorted_obj).keys().tolist():\n",
    "#         label.append(str(i)+str(j))\n",
    "# print(label)\n",
    "#pd.value_counts(df.groupby([df.reportingperiodendingdate, df.subvented])).keys().tolist()\n",
    "\n",
    "\n",
    "#df.loc[df.underwriting_true==0].currentdelinquencystatus.plot(kind='hist', bins=10)\n",
    "#df.groupby([df.subvented]).plot(kind='scatter', x='originalinterestratepercentage',y='currentdelinquencystatus')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Feature Column for Subvented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added Column for :   subvented_[\"1\",\"2\"]\n",
      "Added Column for :   subvented_[\"2\"]\n",
      "Added Column for :   subvented_[\"1\"]\n",
      "Added Column for :   subvented_[\"0\"]\n",
      "New Dataframe shape :  (502928, 44)\n"
     ]
    }
   ],
   "source": [
    "# create feature columns for subvented\n",
    "def map_subvented(*args):\n",
    "    columns = [col for col in args]\n",
    "    for column in columns:\n",
    "        if column == code:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "codes = pd.value_counts(df.subvented).index.tolist()\n",
    "\n",
    "for code in codes:\n",
    "        df['subvented_{}'.format(code)] = list(map(map_subvented, df.subvented))\n",
    "        print('Added Column for :   subvented_'+code)\n",
    "print('New Dataframe shape : ', df.shape)\n",
    "df.drop(['subvented'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vehicle New or Used code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indicate whether the vehicle financed is new or used at the time of origination. 1: New, 2: Used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 2.0]\n",
       "Categories (2, float64): [1.0, 2.0]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.vehiclenewusedcode.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['vehiclenewusedcode']=df.vehiclenewusedcode.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#draw(df.vehiclenewusedcode, title='Vehicle New or Used code', ylabel='Number of Loans', sort=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Feature Column for New or Used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added Column for :   vehiclenew_true\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    436027\n",
       "0     66901\n",
       "Name: vehiclenew_true, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def map_vehiclenewusedcode_true(*args):\n",
    "    columns = [col for col in args]\n",
    "    for column in columns:\n",
    "        if column == 1:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "df['vehiclenew_true'] = list(map(map_vehiclenewusedcode_true, df.vehiclenewusedcode))\n",
    "print('Added Column for :   vehiclenew_true')\n",
    "df.drop(['vehiclenewusedcode'], axis=1, inplace=True)\n",
    "pd.value_counts(df.vehiclenew_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Vehicles mean deliquency days by the reporting period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#df.groupby([df.reportingperiodendingdate,df.vehiclenew_true]).currentdelinquencystatus.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vehicle Type code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indicate the code describing the vehicle type. 1: Car, 2:\n",
    "Truck, 3: SUV, 4: Motorcycle, 98: Other, 99: Unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 1., 3.])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.vehicletypecode.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['vehicletypecode']=df.vehicletypecode.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['vehicletypecode']=df.vehicletypecode.replace(1.0,'Car').replace(2.0,'Truck').replace(3.0,'SUV').replace(4.0,'Motorcycle').replace(98.0,'Other').replace(99.0,'Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#draw(df.vehicletypecode, title='Vehicle Type Code', ylabel='Number of Loans', sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.vehicletypecode.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.vehicletypecode.isna().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Features for Vehicle Type Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def map_vehicletypecode(*args):\n",
    "    columns = [col for col in args]\n",
    "    for column in columns:\n",
    "        if column == code:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "codes = pd.value_counts(df.vehicletypecode).index.tolist()\n",
    "\n",
    "for code in codes:\n",
    "        df['vehicletypecode_{}'.format(code)] = list(map(map_vehicletypecode, df.vehicletypecode))\n",
    "        print('Added Column for :   vehicletypecode_'+code)\n",
    "print('New Dataframe shape : ', df.shape)\n",
    "df.drop(['vehicletypecode'], axis=1, inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vehicle Manufacturer Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['FORD', 'LINC'], dtype=object)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.vehiclemanufacturername.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.vehiclemanufacturername.isna().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Features for Vehicle Manufacturer Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added Column for :   vehiclemanufacturername_FORD\n",
      "Added Column for :   vehiclemanufacturername_LINC\n",
      "New Dataframe shape :  (502928, 47)\n"
     ]
    }
   ],
   "source": [
    "def map_vehiclemanufacturername(*args):\n",
    "    columns = [col for col in args]\n",
    "    for column in columns:\n",
    "        if column == code:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "codes = pd.value_counts(df.vehiclemanufacturername).index.tolist()\n",
    "\n",
    "for code in codes:\n",
    "        df['vehiclemanufacturername_{}'.format(code)] = list(map(map_vehiclemanufacturername, df.vehiclemanufacturername))\n",
    "        print('Added Column for :   vehiclemanufacturername_'+code)\n",
    "print('New Dataframe shape : ', df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(502928, 46)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(['vehiclemanufacturername'], axis=1, inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vehicle Model Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['F-250', 'F-150', 'Fusion', 'Flex', 'Escape', 'Ranger', 'Explorer',\n",
       "       'Focus', 'Edge', 'F-350', 'Transit Connect', 'F-450', 'Taurus',\n",
       "       'MKZ', 'E-350', 'Fiesta', 'Mustang', 'MKX', 'MKT', 'Expedition',\n",
       "       'E-150', 'E-250', 'MKS', 'F-550', 'C-Max', 'F-59', 'Navigator',\n",
       "       'E-450', 'MKC', 'T-250', 'T-350', 'T-150', 'Town Car', 'Excursion',\n",
       "       'Thunderbird', 'Aviator', 'Continental'], dtype=object)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.vehiclemodelname.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.vehiclemodelname.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added Column for :   vehiclemodelname_F-150\n",
      "Added Column for :   vehiclemodelname_Escape\n",
      "Added Column for :   vehiclemodelname_Fusion\n",
      "Added Column for :   vehiclemodelname_Focus\n",
      "Added Column for :   vehiclemodelname_Explorer\n",
      "Added Column for :   vehiclemodelname_Edge\n",
      "Added Column for :   vehiclemodelname_F-250\n",
      "Added Column for :   vehiclemodelname_F-350\n",
      "Added Column for :   vehiclemodelname_Mustang\n",
      "Added Column for :   vehiclemodelname_Fiesta\n",
      "Added Column for :   vehiclemodelname_MKX\n",
      "Added Column for :   vehiclemodelname_Expedition\n",
      "Added Column for :   vehiclemodelname_Transit Connect\n",
      "Added Column for :   vehiclemodelname_T-250\n",
      "Added Column for :   vehiclemodelname_MKZ\n",
      "Added Column for :   vehiclemodelname_Taurus\n",
      "Added Column for :   vehiclemodelname_C-Max\n",
      "Added Column for :   vehiclemodelname_MKC\n",
      "Added Column for :   vehiclemodelname_T-350\n",
      "Added Column for :   vehiclemodelname_F-550\n",
      "Added Column for :   vehiclemodelname_Flex\n",
      "Added Column for :   vehiclemodelname_Navigator\n",
      "Added Column for :   vehiclemodelname_T-150\n",
      "Added Column for :   vehiclemodelname_F-450\n",
      "Added Column for :   vehiclemodelname_E-350\n",
      "Added Column for :   vehiclemodelname_MKS\n",
      "Added Column for :   vehiclemodelname_MKT\n",
      "Added Column for :   vehiclemodelname_E-250\n",
      "Added Column for :   vehiclemodelname_Continental\n",
      "Added Column for :   vehiclemodelname_E-450\n",
      "Added Column for :   vehiclemodelname_E-150\n",
      "Added Column for :   vehiclemodelname_F-59\n",
      "Added Column for :   vehiclemodelname_Ranger\n",
      "Added Column for :   vehiclemodelname_Town Car\n",
      "Added Column for :   vehiclemodelname_Thunderbird\n",
      "Added Column for :   vehiclemodelname_Excursion\n",
      "Added Column for :   vehiclemodelname_Aviator\n",
      "New Dataframe shape :  (502928, 83)\n"
     ]
    }
   ],
   "source": [
    "def map_vehiclemodelname(*args):\n",
    "    columns = [col for col in args]\n",
    "    for column in columns:\n",
    "        if column == code:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "codes = pd.value_counts(df.vehiclemodelname).index.tolist()\n",
    "\n",
    "for code in codes:\n",
    "        df['vehiclemodelname_{}'.format(code)] = list(map(map_vehiclemodelname, df.vehiclemodelname))\n",
    "        print('Added Column for :   vehiclemodelname_'+code)\n",
    "print('New Dataframe shape : ', df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(502928, 82)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(['vehiclemodelname'], axis=1, inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vehicle Model Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2011., 2012., 2009., 2010., 2013., 2008., 2014., 2015., 2006.,\n",
       "       2007., 2004., 2005., 2016., 2017., 2003., 1997., 2001., 2002.,\n",
       "       2018.])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.vehiclemodelyear.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.vehiclemodelyear.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['vehiclemodelyear']=df.vehiclemodelyear.astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added Column for :   vehiclemodelyear_2016.0\n",
      "Added Column for :   vehiclemodelyear_2015.0\n",
      "Added Column for :   vehiclemodelyear_2014.0\n",
      "Added Column for :   vehiclemodelyear_2017.0\n",
      "Added Column for :   vehiclemodelyear_2013.0\n",
      "Added Column for :   vehiclemodelyear_2012.0\n",
      "Added Column for :   vehiclemodelyear_2011.0\n",
      "Added Column for :   vehiclemodelyear_2010.0\n",
      "Added Column for :   vehiclemodelyear_2009.0\n",
      "Added Column for :   vehiclemodelyear_2008.0\n",
      "Added Column for :   vehiclemodelyear_2007.0\n",
      "Added Column for :   vehiclemodelyear_2006.0\n",
      "Added Column for :   vehiclemodelyear_2004.0\n",
      "Added Column for :   vehiclemodelyear_2005.0\n",
      "Added Column for :   vehiclemodelyear_2002.0\n",
      "Added Column for :   vehiclemodelyear_2003.0\n",
      "Added Column for :   vehiclemodelyear_2001.0\n",
      "Added Column for :   vehiclemodelyear_1997.0\n",
      "Added Column for :   vehiclemodelyear_2018.0\n",
      "New Dataframe shape :  (502928, 101)\n"
     ]
    }
   ],
   "source": [
    "def map_vehiclemodelyear(*args):\n",
    "    columns = [col for col in args]\n",
    "    for column in columns:\n",
    "        if column == code:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "codes = pd.value_counts(df.vehiclemodelyear).index.tolist()\n",
    "\n",
    "for code in codes:\n",
    "        df['vehiclemodelyear_{}'.format(code)] = list(map(map_vehiclemodelyear, df.vehiclemodelyear))\n",
    "        print('Added Column for :   vehiclemodelyear_'+str(code))\n",
    "print('New Dataframe shape : ', df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.drop(['vehiclemodelyear'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vehicle Value Amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([46124., 36702., 22323., ..., 55997., 36219., 47132.])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.vehiclevalueamount.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.vehiclevalueamount.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['vehiclevalueamount']=df.vehiclevalueamount.astype('float')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vehicle Value Source Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1., 98.])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.vehiclevaluesourcecode.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.vehiclevaluesourcecode.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['vehiclevaluesourcecode']=df.vehiclevaluesourcecode.astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added Column for :   vehiclevaluesourcecode_1.0\n",
      "Added Column for :   vehiclevaluesourcecode_98.0\n",
      "New Dataframe shape :  (502928, 102)\n"
     ]
    }
   ],
   "source": [
    "def map_vehiclevaluesourcecode(*args):\n",
    "    columns = [col for col in args]\n",
    "    for column in columns:\n",
    "        if column == code:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "codes = pd.value_counts(df.vehiclevaluesourcecode).index.tolist()\n",
    "\n",
    "for code in codes:\n",
    "        df['vehiclevaluesourcecode_{}'.format(code)] = list(map(map_vehiclevaluesourcecode, df.vehiclevaluesourcecode))\n",
    "        print('Added Column for :   vehiclevaluesourcecode_'+str(code))\n",
    "print('New Dataframe shape : ', df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.drop(['vehiclevaluesourcecode'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(502928, 101)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obligor Geographic Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['MS', 'TN', 'PA', 'NM', 'SC', 'CA', 'GA', 'OH', 'LA', 'TX', 'OR',\n",
       "       'OK', 'KY', 'NH', 'MI', 'IL', 'NY', 'FL', 'NJ', 'WI', 'NV', 'IN',\n",
       "       'IA', 'VA', 'HI', 'MO', 'WV', 'NC', 'MA', 'MD', 'WA', 'CT', 'AL',\n",
       "       'MN', 'ID', 'CO', 'MT', 'NE', 'AZ', 'KS', 'VT', 'ME', 'AR', 'RI',\n",
       "       'SD', 'UT', 'DE', 'AK', 'ND', 'WY', 'DC', 'AE', 'PR'], dtype=object)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.obligorgeographiclocation.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.obligorgeographiclocation.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['obligorgeographiclocation']=df.obligorgeographiclocation.astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added Column for :   obligorgeographiclocation_TX\n",
      "Added Column for :   obligorgeographiclocation_CA\n",
      "Added Column for :   obligorgeographiclocation_FL\n",
      "Added Column for :   obligorgeographiclocation_IL\n",
      "Added Column for :   obligorgeographiclocation_OH\n",
      "Added Column for :   obligorgeographiclocation_MI\n",
      "Added Column for :   obligorgeographiclocation_PA\n",
      "Added Column for :   obligorgeographiclocation_NC\n",
      "Added Column for :   obligorgeographiclocation_NY\n",
      "Added Column for :   obligorgeographiclocation_GA\n",
      "Added Column for :   obligorgeographiclocation_NJ\n",
      "Added Column for :   obligorgeographiclocation_MO\n",
      "Added Column for :   obligorgeographiclocation_VA\n",
      "Added Column for :   obligorgeographiclocation_TN\n",
      "Added Column for :   obligorgeographiclocation_MD\n",
      "Added Column for :   obligorgeographiclocation_IN\n",
      "Added Column for :   obligorgeographiclocation_MA\n",
      "Added Column for :   obligorgeographiclocation_LA\n",
      "Added Column for :   obligorgeographiclocation_WI\n",
      "Added Column for :   obligorgeographiclocation_AZ\n",
      "Added Column for :   obligorgeographiclocation_MN\n",
      "Added Column for :   obligorgeographiclocation_AL\n",
      "Added Column for :   obligorgeographiclocation_OK\n",
      "Added Column for :   obligorgeographiclocation_SC\n",
      "Added Column for :   obligorgeographiclocation_KY\n",
      "Added Column for :   obligorgeographiclocation_CO\n",
      "Added Column for :   obligorgeographiclocation_WA\n",
      "Added Column for :   obligorgeographiclocation_MS\n",
      "Added Column for :   obligorgeographiclocation_IA\n",
      "Added Column for :   obligorgeographiclocation_KS\n",
      "Added Column for :   obligorgeographiclocation_NV\n",
      "Added Column for :   obligorgeographiclocation_CT\n",
      "Added Column for :   obligorgeographiclocation_OR\n",
      "Added Column for :   obligorgeographiclocation_AR\n",
      "Added Column for :   obligorgeographiclocation_WV\n",
      "Added Column for :   obligorgeographiclocation_NE\n",
      "Added Column for :   obligorgeographiclocation_NM\n",
      "Added Column for :   obligorgeographiclocation_UT\n",
      "Added Column for :   obligorgeographiclocation_NH\n",
      "Added Column for :   obligorgeographiclocation_ME\n",
      "Added Column for :   obligorgeographiclocation_DE\n",
      "Added Column for :   obligorgeographiclocation_MT\n",
      "Added Column for :   obligorgeographiclocation_SD\n",
      "Added Column for :   obligorgeographiclocation_ID\n",
      "Added Column for :   obligorgeographiclocation_VT\n",
      "Added Column for :   obligorgeographiclocation_ND\n",
      "Added Column for :   obligorgeographiclocation_HI\n",
      "Added Column for :   obligorgeographiclocation_WY\n",
      "Added Column for :   obligorgeographiclocation_RI\n",
      "Added Column for :   obligorgeographiclocation_AK\n",
      "Added Column for :   obligorgeographiclocation_DC\n",
      "Added Column for :   obligorgeographiclocation_AE\n",
      "Added Column for :   obligorgeographiclocation_PR\n",
      "New Dataframe shape :  (502928, 154)\n"
     ]
    }
   ],
   "source": [
    "def map_obligorgeographiclocation(*args):\n",
    "    columns = [col for col in args]\n",
    "    for column in columns:\n",
    "        if column == code:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "codes = pd.value_counts(df.obligorgeographiclocation).index.tolist()\n",
    "\n",
    "for code in codes:\n",
    "        df['obligorgeographiclocation_{}'.format(code)] = list(map(map_obligorgeographiclocation, df.obligorgeographiclocation))\n",
    "        print('Added Column for :   obligorgeographiclocation_'+str(code))\n",
    "print('New Dataframe shape : ', df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.drop(['obligorgeographiclocation'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(502928, 153)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primary Loan Servicer Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ford Credit'], dtype=object)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.primaryloanservicername.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.drop(['primaryloanservicername'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(502928, 152)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obligor Credit Score Type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the type of the standardized credit score used to\n",
    "evaluate the obligor during the loan origination process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.obligorcreditscoretype.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['obligorcreditscoretype']=df.obligorcreditscoretype.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.obligorcreditscoretype.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Consumer Bureau      423537\n",
       "Commercial Bureau     79391\n",
       "Name: obligorcreditscoretype, dtype: int64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.obligorcreditscoretype.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #remove = ['Unknown/Invalid', 'None' ]\n",
    "\n",
    "# u=pd.value_counts(df.obligorcreditscoretype==str('Unknown/Invalid') & ('None'))\n",
    "# if len(u)<2:\n",
    "#     print('No blank or zero obligor income verification level code')\n",
    "# else: \n",
    "#     print('Number of loans with no obligor income verification level code',':', u[1])\n",
    "#     print('Dropping ', u[1], 'rows and retaining loans with obligor income verification level code')\n",
    "#     #df=df[df.obligorincomeverificationlevelcode>0]\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df=df[~df.obligorcreditscore.astype(str).str.contains('None')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pd.value_counts(df.obligorcreditscoretype=='None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.obligorcreditscore=df.obligorcreditscore.replace('Unknown/Invalid', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pd.value_counts(df.obligorcreditscoretype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df=df[~df.obligorcreditscore.astype(str).str.contains('Unknown/Invalid')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pd.value_counts(df.obligorcreditscoretype=='Unknown/Invalid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df['obligorcreditscoretype']=df.obligorcreditscoretype.astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pd.value_counts(df.obligorcreditscoretype=='Unknown/Invalid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df=df[~df.obligorcreditscore.astype(str).str.contains('Unknown/Invalid')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pd.value_counts(df.obligorcreditscoretype=='Unknown/Invalid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#draw(df.obligorcreditscoretype, title='Obligor Credit Score Type', ylabel='Number of Loans', sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.obligorcreditscoretype.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.groupby([df.reportingperiodendingdate,df.obligorcreditscoretype]).currentdelinquencystatus.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create features for obligator credit score type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added Column for :   credit_type_Consumer Bureau\n",
      "Added Column for :   credit_type_Commercial Bureau\n"
     ]
    }
   ],
   "source": [
    "def map_obligorcreditscoretype(*args):\n",
    "    columns = [col for col in args]\n",
    "    for column in columns:\n",
    "        if column == code:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "codes = pd.value_counts(df.obligorcreditscoretype).index.tolist()\n",
    "\n",
    "for code in codes:\n",
    "        df['credit_type_{}'.format(code)] = list(map(map_obligorcreditscoretype, df.obligorcreditscoretype))\n",
    "        print('Added Column for :   credit_type_'+code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(502928, 153)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(['obligorcreditscoretype'], axis=1, inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obligor Credit Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide the standardized credit score of the obligor used to\n",
    "evaluate the obligor during the loan origination process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.obligorcreditscore.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#draw(df.obligorcreditscore, title='Obligor Credit Score', ylabel='Number of Loans', sort=True, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.obligorcreditscore.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove and Drop rows of Obligor Credit Score with strings('no score', 'none', 'Nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Progra~1\\Anaconda3_4\\envs\\tf_111\\lib\\site-packages\\ipykernel\\__main__.py:2: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Strings in the Columns :  26309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Progra~1\\Anaconda3_4\\envs\\tf_111\\lib\\site-packages\\ipykernel\\__main__.py:5: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strings in data :  ['No Score']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Progra~1\\Anaconda3_4\\envs\\tf_111\\lib\\site-packages\\ipykernel\\__main__.py:7: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n"
     ]
    }
   ],
   "source": [
    "#search for strings in the columns\n",
    "q=df.obligorcreditscore.astype(str).str.contains(r'^([^0-9]*)$', na=False).sum()\n",
    "print('Number of Strings in the Columns : ', q)\n",
    "if q > 0:\n",
    "    u=df[df.obligorcreditscore.astype(str).str.contains(r'^([^0-9]*)$', na=False)].obligorcreditscore.unique()\n",
    "    print('Strings in data : ', u)\n",
    "    df=df[~df.obligorcreditscore.astype(str).str.contains(r'^([^0-9]*)$', na=False)]\n",
    "else:\n",
    "    print('No strings in the Obligor Credit Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Number of blanks in the column\n",
    "# df.obligorcreditscore.astype(str).str.contains(r'^(\\s+)$').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pd.crosstab(df.reportingperiodendingdate, df.obligorcreditscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#df=df[~df.obligorcreditscore.str.contains(r'^([^0-9]*)$', na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.obligorcreditscore.isnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df[df.obligorcreditscore.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df=df.dropna(subset=['obligorcreditscore'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "677    2424\n",
       "818    2315\n",
       "840    2239\n",
       "825    2213\n",
       "830    2192\n",
       "Name: obligorcreditscore, dtype: int64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.obligorcreditscore.value_counts(dropna=False).sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.obligorcreditscore.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['obligorcreditscore']=df.obligorcreditscore.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.groupby([df.reportingperiodendingdate, df.obligorcreditscoretype]).obligorcreditscore.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.drop(['obligorcreditscoretype'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(476619, 153)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obligor Income Verification Level Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indicate the code describing the extent to which the\n",
    "obligor's income was verified during the loan origination\n",
    "process. 1: Not stated, not verified, 2: Stated, not verified,\n",
    "3: Stated, verified but not to level 4 or level 5., 4: Stated,\n",
    "\"level 4\" verifiedLevel 4 income verification = Previous year\n",
    "W-2 or tax returns, and year-to-date pay stubs, if salaried. If\n",
    "self-employed, then obligor provided 2 years of tax returns.,\n",
    "5: Stated, \"level 5\" verifiedLevel 5 income verification = 24\n",
    "months income verification (W-2s, pay stubs, bank\n",
    "statements and/or tax returns). If self-employed, then\n",
    "obligor provided 2 years tax returns plus a CPA certification\n",
    "of the tax returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13241813691858698"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.obligorincomeverificationlevelcode.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['obligorincomeverificationlevelcode']=df.obligorincomeverificationlevelcode.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=df.dropna(subset=['obligorincomeverificationlevelcode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.obligorincomeverificationlevelcode.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#draw(df.obligorincomeverificationlevelcode, title='Obligor Credit Score', ylabel='Number of Loans', sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.obligorincomeverificationlevelcode.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pd.value_counts(df.obligorincomeverificationlevelcode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No blank or zero obligor income verification level code\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(413506, 153)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u=pd.value_counts(df.obligorincomeverificationlevelcode==0)\n",
    "if len(u)<2:\n",
    "    print('No blank or zero obligor income verification level code')\n",
    "else: \n",
    "    print('Number of loans with no obligor income verification level code',':', u[1])\n",
    "    print('Dropping ', u[1], 'rows and retaining loans with obligor income verification level code')\n",
    "    df=df[df.obligorincomeverificationlevelcode>0]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.0, 3.0, 4.0, 5.0, 1.0]\n",
       "Categories (5, float64): [2.0, 3.0, 4.0, 5.0, 1.0]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.obligorincomeverificationlevelcode.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.groupby([df.reportingperiodendingdate, df.obligorincomeverificationlevelcode]).obligorcreditscore.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.groupby([df.reportingperiodendingdate, df.obligorincomeverificationlevelcode]).currentdelinquencystatus.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Feature Columns for Obligor Income Verification Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added Column for :   income_code_2.0\n",
      "Added Column for :   income_code_3.0\n",
      "Added Column for :   income_code_4.0\n",
      "Added Column for :   income_code_1.0\n",
      "Added Column for :   income_code_5.0\n"
     ]
    }
   ],
   "source": [
    "def map_obligorincomeverificationlevelcode(*args):\n",
    "    columns = [col for col in args]\n",
    "    for column in columns:\n",
    "        if column == code:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "codes = pd.value_counts(df.obligorincomeverificationlevelcode).index.tolist()\n",
    "\n",
    "for code in codes:\n",
    "        df['income_code_{}'.format(code)] = list(map(map_obligorincomeverificationlevelcode, df.obligorincomeverificationlevelcode))\n",
    "        print('Added Column for :   income_code_'+str(code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(413506, 157)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(['obligorincomeverificationlevelcode'], axis=1, inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obligor Employment Verification Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indicate the code describing the extent to which the\n",
    "obligor's employment was verified during the loan\n",
    "origination process. 1: Not stated, not verified, 2: Stated,\n",
    "not verified, 3: Stated, level 3 verified Level 3 verified =\n",
    "Direct independent verification with a third party of the\n",
    "obligors current employment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.obligoremploymentverificationcode.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['obligoremploymentverificationcode']=df.obligoremploymentverificationcode.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.0, 3.0, 1.0]\n",
       "Categories (3, float64): [2.0, 3.0, 1.0]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.obligoremploymentverificationcode.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#draw(df.obligoremploymentverificationcode, title='Obligor Employment Verification Code', ylabel='Number of Loans', sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.obligoremploymentverificationcode.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No blank or zero obligor employment verification level code\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(413506, 157)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u=pd.value_counts(df.obligoremploymentverificationcode==0)\n",
    "if len(u)<2:\n",
    "    print('No blank or zero obligor employment verification level code')\n",
    "else: \n",
    "    print('Number of loans with no obligor employment verification level code',':', u[1])\n",
    "    print('Dropping ', u[1], 'rows and retaining loans with obligor employment verification level code')\n",
    "    df=df[df.obligoremploymentverificationcode>0]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.groupby([df.reportingperiodendingdate, df.obligoremploymentverificationcode]).obligorcreditscore.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.groupby([df.reportingperiodendingdate, df.obligoremploymentverificationcode]).currentdelinquencystatus.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create feature Columns for obligor employment verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added Column for :   empl_code_2.0\n",
      "Added Column for :   empl_code_3.0\n",
      "Added Column for :   empl_code_1.0\n"
     ]
    }
   ],
   "source": [
    "def map_obligoremploymentverificationcode(*args):\n",
    "    columns = [col for col in args]\n",
    "    for column in columns:\n",
    "        if column == code:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "codes = pd.value_counts(df.obligoremploymentverificationcode).index.tolist()\n",
    "\n",
    "for code in codes:\n",
    "        df['empl_code_{}'.format(code)] = list(map(map_obligoremploymentverificationcode, df.obligoremploymentverificationcode))\n",
    "        print('Added Column for :   empl_code_'+str(code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(413506, 159)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(['obligoremploymentverificationcode'], axis=1, inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Co-obligator Indicator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indicate whether the loan has a co-obligor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.coobligorindicator.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['coobligorindicator']=df.coobligorindicator.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.coobligorindicator.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False, True]\n",
       "Categories (2, object): [False, True]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.coobligorindicator.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    273598\n",
       "True     139908\n",
       "Name: coobligorindicator, dtype: int64"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(df.coobligorindicator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#draw(df.coobligorindicator, title='Co-Obligator Indicator', ylabel='Number of Loans', sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.groupby([df.reportingperiodendingdate, df.coobligorindicator]).obligorcreditscore.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.groupby([df.reportingperiodendingdate, df.coobligorindicator]).currentdelinquencystatus.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create features for Co-obligator Indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added Column for :   coobligorindicator_true\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(413506, 159)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def map_coobligorindicator_true(*args):\n",
    "    columns = [col for col in args]\n",
    "    for column in columns:\n",
    "        if column == 1:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "df['coobligorindicator_true'] = list(map(map_coobligorindicator_true, df.coobligorindicator))\n",
    "df.drop(['coobligorindicator'], axis=1, inplace=True)\n",
    "print('Added Column for :   coobligorindicator_true')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Servicing Fee Percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.servicingfeepercentage.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.servicingfeepercentage.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.drop(['servicingfeepercentage'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Servicing Flat Fee Amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.servicingflatfeeamount.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.servicingflatfeeamount.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.drop(['servicingflatfeeamount'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reporting Period Actual End Balance Amount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean reporting period actual end balance amount by the reporting period ending date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.reportingperiodactualendbalanceamount.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.groupby(df.reportingperiodendingdate).reportingperiodactualendbalanceamount.mean().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.reportingperiodactualendbalanceamount.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.groupby([df.reportingperiodendingdate]).reportingperiodactualendbalanceamount.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#df.groupby([df.reportingperiodendingdate]).plot(kind='scatter', x='reportingperiodactualendbalanceamount',y='currentdelinquencystatus')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping loans with zero or negative reporting period actual end balance amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# u=pd.value_counts(df.reportingperiodactualendbalanceamount<=0)\n",
    "# if len(u)<2:\n",
    "#     print('No blank or zero or negative reporting period actual end balance amount')\n",
    "# else: \n",
    "#     print('Number of loans with no reporting period actual end balance amount',':', u[1])\n",
    "#     print('Dropping ', u[1], 'rows and retaining loans with reporting period actual end balance amount')\n",
    "#     df=df[df.reportingperiodactualendbalanceamount>0]\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total Actual amount paid...keep or drop?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.totalactualamountpaid.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df=df.dropna(subset=['totalactualamountpaid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.totalactualamountpaid.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# u=pd.value_counts(df.totalactualamountpaid<=0)\n",
    "# if len(u)<2:\n",
    "#     print('No blank or zero or negative total actual amount paid')\n",
    "# else: \n",
    "#     print('Number of loans with no or negative total actual amount paid',':', u[1])\n",
    "#     #print('Dropping ', u[1], 'rows and retaining loans with positive total actual amount paid')\n",
    "#     #df=df[df.totalactualamountpaid>0]\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actual interest collected amount...drop?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.actualinterestcollectedamount.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.actualinterestcollectedamount.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# u=pd.value_counts(df.actualinterestcollectedamount<=0)\n",
    "# if len(u)<2:\n",
    "#     print('No blank or zero actual interest collected amount')\n",
    "# else: \n",
    "#     print('Number of loans with no or negative actual interest collected amount',':', u[1])\n",
    "#     #print('Dropping ', u[1], 'rows and retaining loans with positive actual interest collected amount')\n",
    "#     #df=df[df.actualinterestcollectedamount>0]\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual principal collected amount..drop ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.actualprincipalcollectedamount.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.actualprincipalcollectedamount.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# u=pd.value_counts(df.actualprincipalcollectedamount<=0)\n",
    "# if len(u)<2:\n",
    "#     print('No blank or zero actual principal collected amount')\n",
    "# else: \n",
    "#     print('Number of loans with zero or negative actual principal collected amount',':', u[1])\n",
    "#     #print('Dropping ', u[1], 'rows and retaining loans with positive actual principal collected amount')\n",
    "#     #df=df[df.actualprincipalcollectedamount>0]\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interest paid through date Drop?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.interestpaidthroughdate.isna().mean()\n",
    "#pd.value_counts(df.interestpaidthroughdate).head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.interestpaidthroughdate.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.interestpaidthroughdate.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping interest paid through date '1900-01-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# u=pd.value_counts(df.interestpaidthroughdate=='1900-01-01')\n",
    "# if len(u)<2:\n",
    "#     print('No blank or zero interest paid throughdate as 1900-01-01')\n",
    "# else: \n",
    "#     print('Number of loans with zero or 1900-01-01 as  interest paid throughdate',':', u[1])\n",
    "#     #print('Dropping ', u[1], 'rows and retaining loans with correct interest paid throughdate')\n",
    "#     #df=df[df.interestpaidthroughdate>'1900-01-01']\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping interest paid through data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df.drop(['interestpaidthroughdate'], axis=1, inplace=True)\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Days from origination to first payment date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.originalfirstpaymentdate.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2012-02-29', '2012-03-31', '2012-04-30', '2012-05-31',\n",
       "       '2012-06-30', '2012-07-31', '2012-08-31', '2012-09-30',\n",
       "       '2012-10-31', '2012-11-30', '2012-12-31', '2013-01-31',\n",
       "       '2013-02-28', '2013-03-31', '2013-04-30', '2013-05-31',\n",
       "       '2013-06-30', '2013-07-31', '2013-08-31', '2013-09-30',\n",
       "       '2013-10-31', '2013-11-30', '2013-12-31', '2014-01-31',\n",
       "       '2014-02-28', '2014-03-31', '2014-04-30', '2014-05-31',\n",
       "       '2014-06-30', '2014-07-31', '2014-08-31', '2014-09-30',\n",
       "       '2014-10-31', '2014-11-30', '2014-12-31', '2015-01-31',\n",
       "       '2015-02-28', '2015-03-31', '2015-04-30', '2015-05-31',\n",
       "       '2015-06-30', '2015-07-31', '2015-08-31', '2015-09-30',\n",
       "       '2015-10-31', '2015-11-30', '2015-12-31', '2016-01-31',\n",
       "       '2016-03-31', '2016-04-30', '2016-02-29', '2016-05-31',\n",
       "       '2016-06-30', '2016-07-31', '2016-08-31', '2016-09-30',\n",
       "       '2016-10-31', '2016-11-30', '2016-12-31', '2017-01-31'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.originalfirstpaymentdate.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['daystofirstpayment'] = pd.to_datetime(df['originalfirstpaymentdate'])-pd.to_datetime(df['originationdate'])\n",
    "#draw a chart for visual look and analysis\n",
    "#draw(df.daystofirstpayment, title='Days to First Payment', ylabel='Number of Loans', sort = True, n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.daystofirstpayment.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a new feature for number of days to first payment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#remove days string for machine learning\n",
    "df['daystofirstpayment']=df.daystofirstpayment.map(lambda x: np.nan if pd.isnull(x) else x.days)\n",
    "#display last five rows\n",
    "#df.daystofirstpayment.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of loans with zero days to first payment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of loans with zero days to first payment : 40\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(413506, 158)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u=pd.value_counts(df.daystofirstpayment==0)\n",
    "if len(u)<2:\n",
    "    print('No blank or zero days to first payment')\n",
    "else: \n",
    "    print('Number of loans with zero days to first payment',':', u[1])\n",
    "    #print('Dropping ', u[1], 'rows and retaining loans with positive total actual amount paid')\n",
    "    #df=df[df.daystofirstpayment>0]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.groupby([df.reportingperiodendingdate]).daystofirstpayment.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#df.groupby([df.reportingperiodendingdate]).plot(kind='scatter', x='daystofirstpayment',y='currentdelinquencystatus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(413506, 157)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(['originalfirstpaymentdate'], axis=1, inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Payment Type Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.paymenttypecode.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.drop(['paymenttypecode'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grace Period Number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indicate the number of months during which time interest accrues but no payments are due from the obligor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.graceperiodnumber.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#draw(df.graceperiodnumber, title='Grace period Number', ylabel='Number of Loans', sort = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.graceperiodnumber.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.groupby([df.reportingperiodendingdate]).graceperiodnumber.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of loans with zero grace period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# u=pd.value_counts(df.graceperiodnumber==0)\n",
    "# if len(u)<2:\n",
    "#     print('No blank or zero grace period number')\n",
    "# else: \n",
    "#     print('Number of loans with zero grace period number',':', u[1])\n",
    "#     #print('Dropping ', u[1], 'rows and retaining loans with positive grace period number')\n",
    "#     #df=df[df.graceperiodnumber>0]\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asset added indicator...not included"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indicate yes or no whether the asset was added during the\n",
    "reporting period. Instruction: A response to this data point\n",
    "is only required when assets are added to the asset pool\n",
    "after the final prospectus is filed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['assetaddedindicator']=df.assetaddedindicator.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.assetaddedindicator.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.assetaddedindicator.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#draw(df.assetaddedindicator, title='Asset Added Indicator', ylabel='Proportion of Loans', sort = False, n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.assetaddedindicator.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# u=pd.value_counts(df.assetaddedindicator!=False)\n",
    "# if len(u)<2:\n",
    "#     print('No blank or zero Asset Added Indicator')\n",
    "# else: \n",
    "#     print('Number of loans with zero or blank Asset Added Indicator',':', u[1])\n",
    "#     #print('Dropping ', u[1], 'rows and retaining loans with positive asset added indicator')\n",
    "#     #df=df[df.assetaddedindicator>0]\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.groupby([df.reportingperiodendingdate, df.assetaddedindicator]).currentdelinquencystatus.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.groupby([df.reportingperiodendingdate, df.assetaddedindicator]).obligorcreditscore.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df.drop(['assetaddedindicator'], axis=1, inplace=True)\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reporting Period Modification Indicator.. added for now. would it reveal delinquency?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indicates yes or no whether the loan was modified from its\n",
    "original terms during the reporting period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.reportingperiodmodificationindicator.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df['reportingperiodmodificationindicator']=df.reportingperiodmodificationindicator.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#draw(df.reportingperiodmodificationindicator, title='Reporting Period Modification Error', ylabel='Proportion of Loans', sort = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.reportingperiodmodificationindicator.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.groupby([df.reportingperiodendingdate, df.reportingperiodmodificationindicator]).currentdelinquencystatus.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.groupby([df.reportingperiodendingdate, df.reportingperiodmodificationindicator]).obligorcreditscore.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Features for Reporting Period Modification Indicator True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def map_reportingperiodmodificationindicator_true(*args):\n",
    "#     columns = [col for col in args]\n",
    "#     for column in columns:\n",
    "#         if column == 1:\n",
    "#             return 1\n",
    "#         else:\n",
    "#             return 0\n",
    "        \n",
    "# df['reportingperiodmodificationindicator_true'] = list(map(map_reportingperiodmodificationindicator_true, df.reportingperiodmodificationindicator))\n",
    "# print('Added Column for :   reportingperiodmodificationindicator_true')\n",
    "# df.drop(['reportingperiodmodificationindicator'], axis=1, inplace=True)\n",
    "# pd.value_counts(df.reportingperiodmodificationindicator_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Servicing Advance Method Code...revealing default status!...Not included"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the code that indicates a servicer's responsibility for\n",
    "advancing principal or interest on delinquent loans. 1: No\n",
    "advancing, 2: Interest only, 3: Principal only, 4: Principal and\n",
    "Interest, 99: Unavailable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.servicingadvancemethodcode.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df['servicingadvancemethodcode']=df.servicingadvancemethodcode.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#draw(df.servicingadvancemethodcode, title='Serving Advance Method Code', ylabel='Number of Loans', sort = True, n=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.servicingadvancemethodcode.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.groupby([df.reportingperiodendingdate, df.servicingadvancemethodcode]).obligorcreditscore.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.groupby([df.reportingperiodendingdate, df.servicingadvancemethodcode]).currentdelinquencystatus.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Feature Columns for Servicing Advance Method Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def map_servicingadvancemethodcode(*args):\n",
    "#     columns = [col for col in args]\n",
    "#     for column in columns:\n",
    "#         if column == code:\n",
    "#             return 1\n",
    "#         else:\n",
    "#             return 0\n",
    "# codes = pd.value_counts(df.servicingadvancemethodcode).index.tolist()\n",
    "\n",
    "# for code in codes:\n",
    "#         df['servicingadvancemethod_code_{}'.format(code)] = list(map(map_servicingadvancemethodcode, df.servicingadvancemethodcode))\n",
    "#         print('Added Column for :   servicingadvancemethod_code_'+str(code))\n",
    "# df.drop(['servicingadvancemethodcode'], axis=1, inplace=True)\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropped Other Principal Adjustment Amount...negative amt?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indicate any other amounts that caused the principal balance of the loan to be decreased or increased during the reporting period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.otherprincipaladjustmentamount.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.otherprincipaladjustmentamount.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# u=pd.value_counts(df.otherprincipaladjustmentamount<=0)\n",
    "# if len(u)<2:\n",
    "#     print('No blank other principal adjustment amount')\n",
    "# else: \n",
    "#     print('Number of loans with zero or negative principal adjustment amount',':', u[1])\n",
    "#     #print('Dropping ', u[1], 'rows and retaining loans with other principal adjustment amount')\n",
    "#     #df=df[df.otherprincipaladjustmentamount>0]\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.drop(['otherprincipaladjustmentamount'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Dropped Zero Balance Effective Date..check correlation with target(current)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide the date on which the loan balance was reduced to\n",
    "zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.zerobalanceeffectivedate.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.zerobalanceeffectivedate.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Dropped now.....Adding new features for Days to Zero Balance Effective Date from Origination Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for i in pd.value_counts(df.zerobalanceeffectivedate).keys().tolist():\n",
    "#     if i>cutOffForOriginationDate:\n",
    "#         df['zerobalanceeffectivedate_calc'] = pd.to_datetime(df['zerobalanceeffectivedate'])-pd.to_datetime(df['originationdate'])\n",
    "# df['zerobalanceeffectivedate_calc']=df.zerobalanceeffectivedate_calc.map(lambda x: np.nan if pd.isnull(x) else x.days)\n",
    "# print('Added Column for :   zerobalanceeffectivedate_calc')\n",
    "#df.zerobalanceeffectivedate_calc.replace(np.nan, 0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.zerobalanceeffectivedate_calc.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.zerobalanceeffectivedate_calc.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.zerobalanceeffectivedate_calc.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df.drop(['zerobalanceeffectivedate'], axis=1, inplace=True)\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.drop(['zerobalanceeffectivedate_calc'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropped now Zero Balance Code..correlation with being current"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide the code that indicates the reason the loan's\n",
    "balance was reduced to zero. 1: Prepaid or Matured, 2:\n",
    "Third-party Sale, 3: Repurchased or Replaced, 4: Chargedoff,\n",
    "5: Servicing Transfer, 99: Unavailable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.zerobalancecode.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['zerobalancecode']=df.zerobalancecode.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[], [\"1\"], [\"3\"], [\"4\"]]\n",
       "Categories (4, object): [[], [\"1\"], [\"3\"], [\"4\"]]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.zerobalancecode.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]       406415\n",
       "[\"1\"]      6580\n",
       "[\"4\"]       397\n",
       "[\"3\"]       114\n",
       "Name: zerobalancecode, dtype: int64"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(df.zerobalancecode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# draw(df.zerobalancecode, title='Zero Balance Code', ylabel='Number of Loans', sort = True, n=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create feature column for zero balance code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added Column for :   zerobalance_[]\n",
      "Added Column for :   zerobalance_[\"1\"]\n",
      "Added Column for :   zerobalance_[\"4\"]\n",
      "Added Column for :   zerobalance_[\"3\"]\n"
     ]
    }
   ],
   "source": [
    "def map_zerobalancecode(*args):\n",
    "    columns = [col for col in args]\n",
    "    for column in columns:\n",
    "        if column == code:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "codes = pd.value_counts(df.zerobalancecode).index.tolist()\n",
    "\n",
    "for code in codes:\n",
    "        df['zerobalance_{}'.format(code)] = list(map(map_zerobalancecode, df.zerobalancecode))\n",
    "        print('Added Column for :   zerobalance_'+code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['label']=df['zerobalance_[\"4\"]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    413109\n",
       "1       397\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(413506, 157)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(['zerobalancecode', 'zerobalance_[]', 'zerobalance_[\"1\"]', 'zerobalance_[\"3\"]'], axis=1, inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add External S&P Experian default index and historical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.to_csv(path+\"prod/processed_prod_Dec_to_Sep_ns_other_before_sp.csv\", chunksize=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df=pd.read_csv(path+'prod/processed_prod_Dec_to_Sep_ns_other_before_sp.csv', \n",
    "#                #usecols=use_list, \n",
    "#                #sep='\\t',\n",
    "#                #compression=bz2,\n",
    "#                #nrows=nrows,\n",
    "#                low_memory=True, \n",
    "#               #index_col='abs_loan.reportingperiodendingdate', \n",
    "#                parse_dates=True\n",
    "#               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.drop(['reportingperiodbeginningdate'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=df.set_index('reportingperiodendingdate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['cik']=df.cik.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.cik.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['065739000603', '065739000607', '065739000608', ...,\n",
       "       '065739066534', '065739066535', '065739066537'], dtype=object)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.assetnumber.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.value_counts(df.assetnumber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.assetnumber=df.assetnumber.astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test=df[df.assetnumber=='16319243']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test.to_csv(path+'datasets/test_for_duplicates.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.assetnumber=df.assetnumber.astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1=pd.read_csv(path+'datasets/s&pExperianAutoDefaultIndex.csv', index_col=0)\n",
    "df=df.join(df1)\n",
    "df2=pd.read_csv(path+'datasets/experianHistDefaultRates.csv', index_col=0)\n",
    "df=df.join(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>assetnumber</th>\n",
       "      <th>originationdate</th>\n",
       "      <th>originalloanamount</th>\n",
       "      <th>originalloanterm</th>\n",
       "      <th>originalinterestratepercentage</th>\n",
       "      <th>interestcalculationtypecode</th>\n",
       "      <th>vehiclevalueamount</th>\n",
       "      <th>obligorcreditscore</th>\n",
       "      <th>paymenttoincomepercentage</th>\n",
       "      <th>reportingperiodending_2017-12-31</th>\n",
       "      <th>...</th>\n",
       "      <th>coobligorindicator_true</th>\n",
       "      <th>daystofirstpayment</th>\n",
       "      <th>zerobalance_[\"4\"]</th>\n",
       "      <th>label</th>\n",
       "      <th>S&amp;P/Experian Auto Default Index</th>\n",
       "      <th>AutoIndex</th>\n",
       "      <th>BankCardIndex</th>\n",
       "      <th>FirstMortgageIndex</th>\n",
       "      <th>SecondMortgageIndex</th>\n",
       "      <th>CompositeIndex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-12-31</th>\n",
       "      <td>065739000603</td>\n",
       "      <td>2012-01-31</td>\n",
       "      <td>39000.00</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.0599</td>\n",
       "      <td>1.0</td>\n",
       "      <td>46124.0</td>\n",
       "      <td>767.0</td>\n",
       "      <td>0.0809</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>1.1</td>\n",
       "      <td>3.44</td>\n",
       "      <td>0.68</td>\n",
       "      <td>1.22</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-31</th>\n",
       "      <td>065739000607</td>\n",
       "      <td>2012-01-31</td>\n",
       "      <td>39818.67</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.0779</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36702.0</td>\n",
       "      <td>620.0</td>\n",
       "      <td>0.1289</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>1.1</td>\n",
       "      <td>3.44</td>\n",
       "      <td>0.68</td>\n",
       "      <td>1.22</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-31</th>\n",
       "      <td>065739000608</td>\n",
       "      <td>2012-01-31</td>\n",
       "      <td>22311.43</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.0659</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22323.0</td>\n",
       "      <td>723.0</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>1.1</td>\n",
       "      <td>3.44</td>\n",
       "      <td>0.68</td>\n",
       "      <td>1.22</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-31</th>\n",
       "      <td>065739000611</td>\n",
       "      <td>2012-01-31</td>\n",
       "      <td>28688.62</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.0789</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25412.0</td>\n",
       "      <td>673.0</td>\n",
       "      <td>0.0727</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>1.1</td>\n",
       "      <td>3.44</td>\n",
       "      <td>0.68</td>\n",
       "      <td>1.22</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-31</th>\n",
       "      <td>065739000612</td>\n",
       "      <td>2012-01-31</td>\n",
       "      <td>45204.00</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.0190</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42589.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>0.1028</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>1.1</td>\n",
       "      <td>3.44</td>\n",
       "      <td>0.68</td>\n",
       "      <td>1.22</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 162 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             assetnumber originationdate  originalloanamount  \\\n",
       "2017-12-31  065739000603      2012-01-31            39000.00   \n",
       "2017-12-31  065739000607      2012-01-31            39818.67   \n",
       "2017-12-31  065739000608      2012-01-31            22311.43   \n",
       "2017-12-31  065739000611      2012-01-31            28688.62   \n",
       "2017-12-31  065739000612      2012-01-31            45204.00   \n",
       "\n",
       "            originalloanterm  originalinterestratepercentage  \\\n",
       "2017-12-31              73.0                          0.0599   \n",
       "2017-12-31              73.0                          0.0779   \n",
       "2017-12-31              73.0                          0.0659   \n",
       "2017-12-31              73.0                          0.0789   \n",
       "2017-12-31              73.0                          0.0190   \n",
       "\n",
       "            interestcalculationtypecode  vehiclevalueamount  \\\n",
       "2017-12-31                          1.0             46124.0   \n",
       "2017-12-31                          1.0             36702.0   \n",
       "2017-12-31                          1.0             22323.0   \n",
       "2017-12-31                          1.0             25412.0   \n",
       "2017-12-31                          1.0             42589.0   \n",
       "\n",
       "            obligorcreditscore  paymenttoincomepercentage  \\\n",
       "2017-12-31               767.0                     0.0809   \n",
       "2017-12-31               620.0                     0.1289   \n",
       "2017-12-31               723.0                     0.0590   \n",
       "2017-12-31               673.0                     0.0727   \n",
       "2017-12-31               689.0                     0.1028   \n",
       "\n",
       "            reportingperiodending_2017-12-31       ...        \\\n",
       "2017-12-31                                 1       ...         \n",
       "2017-12-31                                 1       ...         \n",
       "2017-12-31                                 1       ...         \n",
       "2017-12-31                                 1       ...         \n",
       "2017-12-31                                 1       ...         \n",
       "\n",
       "            coobligorindicator_true  daystofirstpayment  zerobalance_[\"4\"]  \\\n",
       "2017-12-31                        0                  29                  0   \n",
       "2017-12-31                        1                  29                  0   \n",
       "2017-12-31                        1                  29                  0   \n",
       "2017-12-31                        1                  29                  0   \n",
       "2017-12-31                        0                  29                  0   \n",
       "\n",
       "            label  S&P/Experian Auto Default Index  AutoIndex  BankCardIndex  \\\n",
       "2017-12-31      0                           0.0107        1.1           3.44   \n",
       "2017-12-31      0                           0.0107        1.1           3.44   \n",
       "2017-12-31      0                           0.0107        1.1           3.44   \n",
       "2017-12-31      0                           0.0107        1.1           3.44   \n",
       "2017-12-31      0                           0.0107        1.1           3.44   \n",
       "\n",
       "            FirstMortgageIndex  SecondMortgageIndex  CompositeIndex  \n",
       "2017-12-31                0.68                 1.22            0.91  \n",
       "2017-12-31                0.68                 1.22            0.91  \n",
       "2017-12-31                0.68                 1.22            0.91  \n",
       "2017-12-31                0.68                 1.22            0.91  \n",
       "2017-12-31                0.68                 1.22            0.91  \n",
       "\n",
       "[5 rows x 162 columns]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df.drop(['cik', 'assetnumber','originationdate'], axis=1, inplace=True)\n",
    "# df.shape     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# change columns to lower case and remove prefix to enable pandas to work\n",
    "#column_list=[x.lower() for x in (column_list)]\n",
    "#df.columns=df.columns.str.replace('abs_loan.','')\n",
    "# convert objects to numeric\n",
    "#df=df.convert_objects(convert_numeric=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loan Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deliquency Buckets Current Vs Non-Current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LABELS = ('Current', 'Not Current')\n",
    "# count_classes = pd.value_counts(df.currentdelinquencystatus>0, sort = True)\n",
    "# count_classes.plot(kind = 'bar', rot=0)\n",
    "# plt.xticks(range(2), LABELS)\n",
    "# plt.title('Deliquency Class')\n",
    "# plt.ylabel(\"Number of Loans\")\n",
    "# plt.show()\n",
    "# print('Number of loans Current :', count_classes[0],'   ', 'Number of loans Not Current :', count_classes[1],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.currentdelinquencystatus.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.currentdelinquencystatus.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# u=pd.value_counts(df.currentdelinquencystatus==''.index) \n",
    "# if len(u)<2:\n",
    "#     print('No blank current delinquency status')\n",
    "# else: \n",
    "#     print('Number of loans with blank current delinquency status',':', u[1])\n",
    "#     #print('Dropping ', u[1], 'rows and retaining loans with correct interest paid throughdate')\n",
    "#     #df=df[df.interestpaidthroughdate>'1900-01-01']\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Creation for Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def map_label(*args):\n",
    "#     columns = [col for col in args]\n",
    "#     for column in columns:\n",
    "#         if column > 0:\n",
    "#             return 1\n",
    "#         elif column == 0:\n",
    "#             return 0\n",
    "        \n",
    "# df['label'] = list(map(map_label, df.currentdelinquencystatus ))\n",
    "\n",
    "# LABELS = ('Current', 'Default')\n",
    "# count_classes = pd.value_counts(df.label, sort = True)\n",
    "# count_classes.plot(kind = 'bar', rot=0)\n",
    "# plt.xticks(range(2), LABELS)\n",
    "# plt.title('Revised Deliquency Class')\n",
    "# plt.ylabel(\"Number of Loans\")\n",
    "# plt.show()\n",
    "# print('Number of loans Current :', count_classes[0],'   ', 'Number of loans Defaulted :', count_classes[1],)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loan Balance Amount at the End of Reporting Period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# current_df = df[df.label==0]\n",
    "# not_current_df = df[df.label==1]\n",
    "# bins = np.linspace(0, 100000, 100)\n",
    "# plt.hist(current_df.reportingperiodactualendbalanceamount, bins, alpha=0.6, \n",
    "#          #density=True, \n",
    "#          label='CURRENT')\n",
    "# plt.hist(not_current_df.reportingperiodactualendbalanceamount, bins, alpha=1, \n",
    "#          #density=True, \n",
    "#          label='NOT CURRENT')\n",
    "# plt.legend(loc='upper right')\n",
    "# plt.title(\"Loan Balance Amount at the end of reporting Period\")\n",
    "# plt.xlabel('Loan Balance Amount')\n",
    "# plt.ylabel('Number of of Loans')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual oversampling of default data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #def manual_oversampling(df):\n",
    "# default=df[df.label==1]\n",
    "# print('default: ',default.shape)\n",
    "# b=int((df.shape[0]-default.shape[0])/(default.shape[0]))\n",
    "# print('copy default data ',b, ' times')\n",
    "# b=int(b*manualOversamplingFactor)\n",
    "# print(b)\n",
    "# for i in range(b):\n",
    "#     df=df.append(default, ignore_index=True)\n",
    "# df=df.sample(frac=1).reset_index(drop=True)\n",
    "# draw(df.label, title='Manual Oversampling -Current Vs Non-Current', ylabel='Number of Loans', sort=True)\n",
    "# print(df.shape)\n",
    "# print(pd.value_counts(df.label==1))\n",
    "# #return df\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #manual_oversampling(df)\n",
    "# print(pd.value_counts(df.label==1))\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversampling with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from imblearn.over_sampling import SMOTE, ADASYN\n",
    "# x_train, y_train = SMOTE().fit_resample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #Apply SMOTE to create synthetic observations from minority class\n",
    "# #Source:https://github.com/scikit-learn-contrib/imbalanced-learn\n",
    "# from imblearn.over_sampling import SMOTE #Over sampling\n",
    "# sm = SMOTE(ratio='auto',kind='regular')\n",
    "# X_sampled,y_sampled = sm.fit_sample(X,y.values.ravel())\n",
    "\n",
    "# #Percentage of fraudlent records in original data\n",
    "# Source_data_no_fraud_count = len(data[data.Class==0])\n",
    "# Source_data_fraud_count = len(data[data.Class==1])\n",
    "# print('Percentage of fraud counts in original dataset:{}%'.format((Source_data_fraud_count*100)/(Source_data_no_fraud_count+Source_data_fraud_count)))\n",
    "\n",
    "# #Percentage of fraudlent records in sampled data\n",
    "# Sampled_data_no_fraud_count = len(y_sampled[y_sampled==0])\n",
    "# Sampled_data_fraud_count = len(y_sampled[y_sampled==1])\n",
    "# print('Percentage of fraud counts in the new data:{}%'.format((Sampled_data_fraud_count*100)/(Sampled_data_no_fraud_count+Sampled_data_fraud_count)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Naive Random Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from imblearn.over_sampling import RandomOverSampler\n",
    "# ros = RandomOverSampler(random_state=0)\n",
    "# X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "# from collections import Counter\n",
    "# print(sorted(Counter(y_resampled).items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#  Clean up for Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.isnull().any().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pd.value_counts(df.label, dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping NaN rows for the label(current Vs Non-current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.label.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pd.value_counts(df.label, dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pd.value_counts(df.paymenttoincomepercentage, dropna=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping NaN rows for payment to income percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.008577868277606612"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.paymenttoincomepercentage.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.paymenttoincomepercentage.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(413506, 162)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pd.value_counts(df.paymenttoincomepercentage, dropna=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df['servicingflatfeeamount']=df.servicingflatfeeamount.astype('float')\n",
    "#pd.value_counts(df.servicingflatfeeamount, dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Populating blank servicing flat fee amount with zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.servicingflatfeeamount.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pd.value_counts(df.reportingperiodbeginningloanbalanceamount, dropna=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Populate blank rows of reporting period beginning loan balance amount with zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.reportingperiodbeginningloanbalanceamount.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pd.value_counts(df.reportingperiodbeginningloanbalanceamount, dropna=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pd.value_counts(df.otherservicerfeeretainedbyservicer, dropna=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Populate blank other servicer fee retained by servicer with zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.otherservicerfeeretainedbyservicer.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pd.value_counts(df.otherservicerfeeretainedbyservicer, dropna=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pd.value_counts(df.serviceradvancedamount, dropna=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Populate blank servicer advance amount with zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.serviceradvancedamount.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pd.value_counts(df.serviceradvancedamount, dropna=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.isnull().any().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.nextinterestratepercentage.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.nextinterestratepercentage.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.nextinterestratepercentage.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.reportingperiodinterestratepercentage.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.reportingperiodinterestratepercentage.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.reportingperiodinterestratepercentage.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.scheduledinterestamount.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.scheduledinterestamount.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.scheduledprincipalamount.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.scheduledprincipalamount.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.reportingperiodscheduledpaymentamount .isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.reportingperiodscheduledpaymentamount.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Treating Missing values and NaN for Payment to Income Pecentage?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.paymenttoincomepercentage.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Payment to income percentage flag(flag yes when the data is available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.paymenttoincomepercentage.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# u=pd.value_counts(df.paymenttoincomepercentage==0)\n",
    "# print(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def map_paymenttoincomepercentage_true(*args):\n",
    "#     columns = [col for col in args]\n",
    "#     for column in columns:\n",
    "#         if column > 0:\n",
    "#             return 1\n",
    "#         else:\n",
    "#             return 0\n",
    "        \n",
    "# df['paymenttoincomepercentage_true'] = list(map(map_paymenttoincomepercentage_true, df.paymenttoincomepercentage))\n",
    "# print('Added Column for :   paymenttoincomepercentage_true')\n",
    "# pd.value_counts(df.paymenttoincomepercentage_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.to_csv(path+\"prod/processed_prod_Dec_to_Sep_ns_other_before_sp.csv\", chunksize=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.drop(['actualinterestcollectedamount', 'actualprincipalcollectedamount', 'actualothercollectedamount'], axis=1, inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.nextreportingperiodpaymentamountdue.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.nextreportingperiodpaymentamountdue.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.isna().any().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.isnull().any().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Missing Values\n",
    "2. Standard Deviation- Amount of Variation\n",
    "3. Pairwise Correlation\n",
    "4. Multi Co-linearity\n",
    "5. Correlation with the labels\n",
    "6. Cluster Analysis/Dimensionality Reduction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.isnull().any().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Standard Deviation - Amount of Variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Pairwise Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corr=df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corr.to_csv(path+'datasets/corr_prod_ns.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#plt.matshow(df.corr(), figsize=(20,10))\n",
    "plt.matshow(df.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corr.isna().mean().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corr.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corr.isna().mean().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.matshow(corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Correlation with Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corr.label.plot(kind='bar', figsize=(20,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 Check for muti co-linearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eigenvalue, eigenvector = np.linalg.eig(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(path+'datasets/eigenvalue_prod_ns.csv', eigenvalue, delimiter=\",\")\n",
    "np.savetxt(path+'datasets/eigenvector_prod_ns.csv', eigenvector, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "evector=pd.DataFrame(eigenvector, columns=corr.columns.tolist())\n",
    "evector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why select features?\n",
    "1. Some algorithms scale (computationally) poorly with increased dimension\n",
    "2. Irrelevant features can confuse some algorithms\n",
    "3. Redundant features adversely affect regularization\n",
    "4. Removal of features can increase generalization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Feature Selection Methods\n",
    "1. Agnostic\n",
    "    Preprocessing based methods \n",
    "        - Remove a binary feature if 'True' in very few or most samples\n",
    "2. Filter Feature Selection methods\n",
    "        - Use some ranking criteria to rank\n",
    "        - Select the top ranking features\n",
    "3. Wrapper Methods (keep the learning algorithm in the loop)\n",
    "        - Requires repeated runs of the learning algorithm with different set of features\n",
    "        - Can be computationally expensive\n",
    "4. Heuristics \n",
    "        - much faster than wrapper methods\n",
    "5. Correlation Critera\n",
    "        - Rank features in order of their correlation with the labels\n",
    "6. Forward Search, Backward Search and step-wise search\n",
    "        -Forward Search\n",
    "            Start with no features\n",
    "            Greedily include the most relevant feature\n",
    "            Stop when selected the desired number of features\n",
    "        - Backward Search\n",
    "            Start with all the features\n",
    "            Greedily remove the least relevant feature\n",
    "            Stop when selected the desired number of features\n",
    "        - Stepwise\n",
    "            -reevauate all features after each forward search\n",
    "            -Any feature can be removed after each step\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Huristics "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BIC and AIC\n",
    "Bayesian information criterion (BIC) or Schwarz information criterion (also SIC, SBC, SBIC) is a criterion for model selection among a finite set of models; the model with the lowest BIC is preferred. \n",
    "They are used for choosing best features and often used for comparing nonnested models, which ordinary statistical tests cannot do. The AIC or BIC for a model is usually written in the form [-2logL + kp], where L is the likelihood function, p is the number of parameters in the model, and k is 2 for AIC and log(n) for BIC. In our case, we do not require AIC and BIC techniques for finding the best features due to the simplicity of our model and the number of features being less than 100."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Akaike information criterion (AIC) is an estimator of the relative quality of statistical models for a given set of data. Given a collection of models for the data, AIC estimates the quality of each model, relative to each of the other models. Thus, AIC provides a means for model selection. \n",
    "AIC is an estimate of a constant plus the relative distance between the unknown true likelihood function of the data and the fitted likelihood function of the model, so that a lower AIC means a model is considered to be closer to the truth. BIC is an estimate of a function of the posterior probability of a model being true, under a certain Bayesian setup, so that a lower BIC means that a model is considered to be more likely to be the true model. Both criteria are based on various assumptions and asymptotic approximations. Each, despite its heuristic usefulness, has therefore been criticized as having questionable validity for real world data. But despite various subtle theoretical differences, their only difference in practice is the size of the penalty; BIC penalizes model complexity more heavily. The only way they should disagree is when AIC chooses a larger model than BIC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Union"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is beneficial to combine several methods to obtain good performance. We use FeatureUnion to combine features obtained by PCA and univariate selection.\n",
    "Combining features using this transformer has the benefit that it allows cross validation and grid searches over the whole process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# y=df.label.values\n",
    "# x=df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# from sklearn.feature_selection import SelectKBest\n",
    "# from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "# from sklearn.svm import SVC\n",
    "# # If dataset is way too high-dimensional. Better do PCA:\n",
    "# pca = PCA(n_components=2)\n",
    "\n",
    "# # Maybe some original features where good, too?\n",
    "# selection = SelectKBest(k=1)\n",
    "\n",
    "# # Build estimator from PCA and Univariate selection:\n",
    "\n",
    "# combined_features = FeatureUnion([(\"pca\", pca), (\"univ_select\", selection)])\n",
    "\n",
    "# # Use combined features to transform dataset:\n",
    "# x_features = combined_features.fit(x, y).transform(x)\n",
    "# print(\"Combined space has\", x_features.shape[1], \"features\")\n",
    "\n",
    "# svm = SVC(kernel=\"linear\")\n",
    "\n",
    "# # Do grid search over k, n_components and C:\n",
    "\n",
    "# pipeline = Pipeline([(\"features\", combined_features), (\"svm\", svm)])\n",
    "\n",
    "# param_grid = dict(features__pca__n_components=[1, 2, 3],\n",
    "#                   features__univ_select__k=[1, 2],\n",
    "#                   svm__C=[0.1, 1, 10])\n",
    "\n",
    "# grid_search = GridSearchCV(pipeline, param_grid=param_grid, cv=5, verbose=10)\n",
    "# grid_search.fit(x, y)\n",
    "# print(grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv(path+\"prod/ford_credit_1.csv\", chunksize=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Preparing data for Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # prepare label for scikit-learn\n",
    "# Y=df.label.values\n",
    "# Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # reshape labels for machine learning\n",
    "# Y=Y.reshape(Y.shape[0],1)\n",
    "# Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # prepare input data for scikit-learn\n",
    "# input=df.values\n",
    "# input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # calculate train/test split\n",
    "# len_train = int(len(input)*train_split)\n",
    "# print(len_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # apply train/test split to labels\n",
    "# y_train = Y[0:len_train]\n",
    "# y_test = Y[len_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #reshape input data for machine learning\n",
    "# input=input.reshape(input.shape[0], input.shape[1], 1)\n",
    "# input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # apply train/test split to input data\n",
    "# x_train = input[0:len_train]\n",
    "# x_test = input[len_train:]\n",
    "# x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit-Learn Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "# from sklearn.preprocessing import minmax_scale\n",
    "# from sklearn.preprocessing import MaxAbsScaler\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.preprocessing import RobustScaler\n",
    "# from sklearn.preprocessing import Normalizer\n",
    "# from sklearn.preprocessing import QuantileTransformer\n",
    "# from sklearn.preprocessing import PowerTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# x_scaler=StandardScaler()\n",
    "# x_train = x_scaler.fit_transform(x_train)\n",
    "# x_test = x_scaler.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras Scaling - Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# x_train_keras_scaled = keras.utils.normalize(x_train, axis=-1, order=2)\n",
    "# x_test_keras_scaled = keras.utils.normalize(x_test, axis=-1, order=2)\n",
    "# x_train_keras_scaled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Support Vector Machine Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Support Vector Classification.\n",
    "Similar to SVC with parameter kernel=’linear’, but implemented in terms of liblinear rather than libsvm, so it has more flexibility in the choice of penalties and loss functions and should scale better to large numbers of samples.\n",
    "This class supports both dense and sparse input and the multiclass support is handled according to a one-vs-the-rest scheme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn import svm, neighbors\n",
    "# lsvc=svm.LinearSVC()\n",
    "# clf_lsvc=lsvc.fit(x_train, y_train)\n",
    "# confidence_lsvc=clf_lsvc.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# knn=neighbors.KNeighborsClassifier(n_neighbors=10, n_jobs=-1)\n",
    "# clf_knn=knn.fit(x_train, y_train)\n",
    "# confidence_knn=clf_knn.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Tree Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forests or random decision forests are an ensemble learning method for classification, regression and other tasks, that operate by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees. Random decision forests correct for decision trees' habit of overfitting to their training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rfor=RandomForestClassifier()\n",
    "# clf_rfor = rfor.fit(x_train, y_train)\n",
    "# confidence_rfor=clf_rfor.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lr = LogisticRegression(solver='lbfgs')\n",
    "# clf_lr = lr.fit(x_train, y_train)\n",
    "# confidence_lr=clf_lr.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.naive_bayes import GaussianNB\n",
    "# gnb = GaussianNB()\n",
    "# clf_gnb = gnb.fit(x_train, y_train)\n",
    "# confidence_gnb=clf_gnb.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Learning - GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# model = keras.Sequential()\n",
    "# model.add(keras.layers.GRU(128, activation='relu',  \n",
    "#                            kernel_regularizer=regularizers.l2(0.01), \n",
    "#                            input_shape=(x_train_keras_scaled.shape[1:]), \n",
    "#                            return_sequences=True))\n",
    "# model.add(keras.layers.Dropout(0.3))\n",
    "\n",
    "# model.add(keras.layers.GRU(32, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "# model.add(keras.layers.Dropout(0.2))\n",
    "\n",
    "# model.add(keras.layers.Dense(8, activation='relu',  kernel_regularizer=regularizers.l2(0.01)))\n",
    "# model.add(keras.layers.Dropout(0.3))\n",
    "\n",
    "# model.add(keras.layers.Dense(2, activation='softmax'))\n",
    "\n",
    "# optimizer = tf.keras.optimizers.Adam(lr=1e-3, decay=1e-6)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save the best model\n",
    "#keras.callbacks.Callback()\n",
    "# checkPoint = ModelCheckpoint(filepath = path+'model/'+name+'.h5',\n",
    "#                             save_best_only = True,\n",
    "#                             verbose=0)\n",
    "# tensorboard = TensorBoard(log_dir=path+'logs/{}'.format(name),\n",
    "#                           histogram_freq=0,\n",
    "#                           batch_size=32,\n",
    "#                           write_graph=True,\n",
    "#                           write_images=False)\n",
    "# history = keras.callbacks.History()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "# model.fit(x_train, y_train, epochs=epochs, validation_data=(x_test_keras_scaled, y_test), batch_size=8192, \n",
    "#         # callbacks = [\n",
    "#    # baseLogger,\n",
    "#     #history,\n",
    "#     #tensorboard\n",
    "#     #learningRateScheduler,\n",
    "#     #reduceLROnPlateau\n",
    "#      #    ], \n",
    "#           shuffle=False\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model.save(path+'model/'+name+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test_loss, test_acc = model.evaluate(x_test_keras_scaled, y_test)\n",
    "# print('Test Loss : ',test_loss,' ','Test Accuracy : ', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# y_pred = model.predict_classes(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# np.count_nonzero(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# np.count_nonzero(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#saved_model = load_model(path+'model/ABS_Keras-GRU254GRU128D32D2-adam1540234475.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test_loss, test_acc = saved_model.evaluate(x_test_keras_scaled, y_test)\n",
    "# print('Test Loss : ',test_loss,' ','Test Accuracy : ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Predict Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_pred = x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prediction_gru = model.predict_classes(x_pred)\n",
    "# prediction_lsvc = clf_lsvc.predict(x_pred)\n",
    "# prediction_knn = clf_knn.predict(x_pred)\n",
    "# prediction_rfor = clf_rfor.predict(x_pred)\n",
    "# prediction_lr = clf_lr.predict(x_pred)\n",
    "# prediction_gnb = clf_gnb.predict(x_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predictions = [\n",
    "#   prediction_gru,\n",
    "#     prediction_lsvc,\n",
    "#     prediction_knn,\n",
    "#     prediction_rfor,\n",
    "#     prediction_lr,\n",
    "#     prediction_gnb \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# class_names = ['Current', 'Non-Current']\n",
    "\n",
    "# def plot_confusion_matrix(cm, classes,\n",
    "#                           normalize=False,\n",
    "#                           title='Confusion matrix',\n",
    "#                           cmap=plt.cm.Blues):\n",
    "#     \"\"\"\n",
    "#     This function prints and plots the confusion matrix.\n",
    "#     Normalization can be applied by setting `normalize=True`.\n",
    "#     \"\"\"\n",
    "#     if normalize:\n",
    "#         cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "#         print(\"Normalized confusion matrix\")\n",
    "#     else:\n",
    "#         print('Confusion matrix, without normalization')\n",
    "\n",
    "#     print(cm)\n",
    "\n",
    "#     plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "#     plt.title(title)\n",
    "#     plt.colorbar()\n",
    "#     tick_marks = np.arange(len(classes))\n",
    "#     plt.xticks(tick_marks, classes, rotation=45)\n",
    "#     plt.yticks(tick_marks, classes)\n",
    "\n",
    "#     fmt = '.2f' if normalize else 'd'\n",
    "#     thresh = cm.max() / 2.\n",
    "#     for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "#         plt.text(j, i, format(cm[i, j], fmt),\n",
    "#                  horizontalalignment=\"center\",\n",
    "#                  color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "#     plt.ylabel('True label')\n",
    "#     plt.xlabel('Predicted label')\n",
    "#     plt.tight_layout()\n",
    "\n",
    "# for prediction in predictions:\n",
    "#         print('ROC_AUC_SCORE ; ', roc_auc_score(y_test, prediction))\n",
    "#         # Compute confusion matrix\n",
    "#         cnf_matrix = confusion_matrix(y_test, prediction)\n",
    "#         np.set_printoptions(precision=2)\n",
    "\n",
    "#         # Plot non-normalized confusion matrix\n",
    "#         plt.figure()\n",
    "#         plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "#                           title= 'Confusion matrix')\n",
    "\n",
    "#         # Plot normalized confusion matrix\n",
    "# #         plt.figure()\n",
    "# #         plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=False,\n",
    "# #                           title='Normalized confusion matrix')\n",
    "\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf_111]",
   "language": "python",
   "name": "conda-env-tf_111-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
